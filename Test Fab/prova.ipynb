{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, VecNormalize\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback, CallbackList\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabiodigregorio/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/gymnasium/envs/registration.py:734: UserWarning: \u001b[33mWARN: The environment is being initialised with render_mode='none' that is not in the possible render_modes (['human', 'rgb_array', 'depth_array']).\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/fabiodigregorio/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/gymnasium/envs/registration.py:734: UserWarning: \u001b[33mWARN: The environment is being initialised with render_mode='none' that is not in the possible render_modes (['human', 'rgb_array', 'depth_array']).\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/fabiodigregorio/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/gymnasium/envs/registration.py:734: UserWarning: \u001b[33mWARN: The environment is being initialised with render_mode='none' that is not in the possible render_modes (['human', 'rgb_array', 'depth_array']).\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/fabiodigregorio/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/gymnasium/envs/registration.py:734: UserWarning: \u001b[33mWARN: The environment is being initialised with render_mode='none' that is not in the possible render_modes (['human', 'rgb_array', 'depth_array']).\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Usa SubprocVecEnv per sfruttare il multiprocessing (più veloce di DummyVecEnv)\n",
    "NUM_ENVS = 4  # Numero di ambienti paralleli per accelerare il training\n",
    "\n",
    "# Definiamo la funzione per creare un ambiente vettorializzato\n",
    "def make_env(healthy_z_lower=0.26133111370542855, healthy_z_upper= 1.0967413845523089,contact_force_min= -0.5801381783852236,contact_force_max=0.7870366711904808):\n",
    "    return Monitor(gym.make(\"Ant-v5\",\n",
    "                            reset_noise_scale=0.08325455885769968,\n",
    "                            forward_reward_weight=1.199616714651314,\n",
    "                            ctrl_cost_weight=0.6668668001731599,\n",
    "                            healthy_reward=1.0,\n",
    "                            contact_cost_weight=5e-4,\n",
    "                            healthy_z_range=(healthy_z_lower, healthy_z_upper),\n",
    "                            contact_force_range=(contact_force_min, contact_force_max),\n",
    "                            render_mode='none'))\n",
    "\n",
    "# Creiamo gli ambienti paralleli\n",
    "env = SubprocVecEnv([make_env for _ in range(NUM_ENVS)])\n",
    "env = VecNormalize(env, norm_obs=True, norm_reward=True, clip_obs=10.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabiodigregorio/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/gymnasium/envs/registration.py:734: UserWarning: \u001b[33mWARN: The environment is being initialised with render_mode='none' that is not in the possible render_modes (['human', 'rgb_array', 'depth_array']).\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/fabiodigregorio/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/gymnasium/envs/registration.py:734: UserWarning: \u001b[33mWARN: The environment is being initialised with render_mode='none' that is not in the possible render_modes (['human', 'rgb_array', 'depth_array']).\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/fabiodigregorio/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/gymnasium/envs/registration.py:734: UserWarning: \u001b[33mWARN: The environment is being initialised with render_mode='none' that is not in the possible render_modes (['human', 'rgb_array', 'depth_array']).\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/fabiodigregorio/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/gymnasium/envs/registration.py:734: UserWarning: \u001b[33mWARN: The environment is being initialised with render_mode='none' that is not in the possible render_modes (['human', 'rgb_array', 'depth_array']).\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# Parametri del modello (puoi ottimizzarli con Optuna)\n",
    "\n",
    "model_params = {\n",
    "    \"policy\": \"MlpPolicy\",\n",
    "    \"env\": env,\n",
    "    \"learning_rate\": 1.3481946009485854e-05,  # Usa Optuna per trovare il migliore\n",
    "    \"n_steps\": 6144,\n",
    "    \"batch_size\": 128,\n",
    "    \"n_epochs\": 10,\n",
    "    \"gamma\": 0.9955878438529644,\n",
    "    \"gae_lambda\": 0.9445556509709931,\n",
    "    \"clip_range\": 0.13789333358719322,\n",
    "    \"ent_coef\": 0.03301914704109688,\n",
    "    \"verbose\": 1,\n",
    "    \"tensorboard_log\": \"./ppo_Ant_tensorboard/\",\n",
    "    \"device\": \"mps\"  # Usa GPU se disponibile\n",
    "    \"policy_kwargs\": dict(net_arch=[256, 256, 128])\n",
    "}\n",
    "\n",
    "# Definiamo i callback per salvataggio e valutazione\n",
    "eval_env = SubprocVecEnv([make_env for _ in range(NUM_ENVS)])\n",
    "eval_env = VecNormalize(eval_env, norm_obs=True, norm_reward=True, clip_obs=10.)\n",
    "\n",
    "eval_callback = EvalCallback(eval_env, best_model_save_path=\"./logs/best_model\",\n",
    "                             log_path=\"./logs/\", eval_freq=70000, deterministic=True, render=False)\n",
    "\n",
    "checkpoint_callback = CheckpointCallback(save_freq=10000, save_path=\"./logs/checkpoints/\",\n",
    "                                         name_prefix=\"ppo_ant_checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n",
      "Logging to ./ppo_Ant_tensorboard/PPO_7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60.1     |\n",
      "|    ep_rew_mean     | -105     |\n",
      "| time/              |          |\n",
      "|    fps             | 1359     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 24576    |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 63.1          |\n",
      "|    ep_rew_mean          | -110          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 914           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 53            |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00083612435 |\n",
      "|    clip_fraction        | 0.00144       |\n",
      "|    clip_range           | 0.138         |\n",
      "|    entropy_loss         | -11.4         |\n",
      "|    explained_variance   | -1.4          |\n",
      "|    learning_rate        | 1.35e-05      |\n",
      "|    loss                 | -0.235        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00164      |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.5           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 67.2         |\n",
      "|    ep_rew_mean          | -122         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 815          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 90           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007694909 |\n",
      "|    clip_fraction        | 0.00092      |\n",
      "|    clip_range           | 0.138        |\n",
      "|    entropy_loss         | -11.4        |\n",
      "|    explained_variance   | -0.18        |\n",
      "|    learning_rate        | 1.35e-05     |\n",
      "|    loss                 | -0.295       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.27         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 69.3        |\n",
      "|    ep_rew_mean          | -117        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 779         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000791821 |\n",
      "|    clip_fraction        | 0.00094     |\n",
      "|    clip_range           | 0.138       |\n",
      "|    entropy_loss         | -11.4       |\n",
      "|    explained_variance   | -0.0144     |\n",
      "|    learning_rate        | 1.35e-05    |\n",
      "|    loss                 | -0.277      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00197    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.238       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 56           |\n",
      "|    ep_rew_mean          | -96.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 754          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 162          |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009462962 |\n",
      "|    clip_fraction        | 0.00196      |\n",
      "|    clip_range           | 0.138        |\n",
      "|    entropy_loss         | -11.5        |\n",
      "|    explained_variance   | 0.09         |\n",
      "|    learning_rate        | 1.35e-05     |\n",
      "|    loss                 | -0.259       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00209     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.252        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 59.3          |\n",
      "|    ep_rew_mean          | -104          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 738           |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 199           |\n",
      "|    total_timesteps      | 147456        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00080125715 |\n",
      "|    clip_fraction        | 0.000907      |\n",
      "|    clip_range           | 0.138         |\n",
      "|    entropy_loss         | -11.5         |\n",
      "|    explained_variance   | 0.157         |\n",
      "|    learning_rate        | 1.35e-05      |\n",
      "|    loss                 | -0.21         |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | -0.00188      |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 0.284         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 57.4          |\n",
      "|    ep_rew_mean          | -106          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 730           |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 235           |\n",
      "|    total_timesteps      | 172032        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00096677104 |\n",
      "|    clip_fraction        | 0.00167       |\n",
      "|    clip_range           | 0.138         |\n",
      "|    entropy_loss         | -11.6         |\n",
      "|    explained_variance   | 0.173         |\n",
      "|    learning_rate        | 1.35e-05      |\n",
      "|    loss                 | -0.24         |\n",
      "|    n_updates            | 60            |\n",
      "|    policy_gradient_loss | -0.00227      |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 0.309         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.8         |\n",
      "|    ep_rew_mean          | -110         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 724          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 271          |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009625733 |\n",
      "|    clip_fraction        | 0.00201      |\n",
      "|    clip_range           | 0.138        |\n",
      "|    entropy_loss         | -11.6        |\n",
      "|    explained_variance   | 0.216        |\n",
      "|    learning_rate        | 1.35e-05     |\n",
      "|    loss                 | -0.261       |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.336        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 58.1         |\n",
      "|    ep_rew_mean          | -101         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 720          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 307          |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008547322 |\n",
      "|    clip_fraction        | 0.00123      |\n",
      "|    clip_range           | 0.138        |\n",
      "|    entropy_loss         | -11.6        |\n",
      "|    explained_variance   | 0.224        |\n",
      "|    learning_rate        | 1.35e-05     |\n",
      "|    loss                 | -0.202       |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.359        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 61           |\n",
      "|    ep_rew_mean          | -109         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 342          |\n",
      "|    total_timesteps      | 245760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009197579 |\n",
      "|    clip_fraction        | 0.00167      |\n",
      "|    clip_range           | 0.138        |\n",
      "|    entropy_loss         | -11.7        |\n",
      "|    explained_variance   | 0.247        |\n",
      "|    learning_rate        | 1.35e-05     |\n",
      "|    loss                 | -0.215       |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.367        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 57.7         |\n",
      "|    ep_rew_mean          | -98.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 714          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 378          |\n",
      "|    total_timesteps      | 270336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010028506 |\n",
      "|    clip_fraction        | 0.0017       |\n",
      "|    clip_range           | 0.138        |\n",
      "|    entropy_loss         | -11.7        |\n",
      "|    explained_variance   | 0.284        |\n",
      "|    learning_rate        | 1.35e-05     |\n",
      "|    loss                 | -0.226       |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0022      |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.355        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=1158.50 +/- 50.07\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | 1.16e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 280000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013274682 |\n",
      "|    clip_fraction        | 0.00387      |\n",
      "|    clip_range           | 0.138        |\n",
      "|    entropy_loss         | -11.8        |\n",
      "|    explained_variance   | 0.287        |\n",
      "|    learning_rate        | 1.35e-05     |\n",
      "|    loss                 | -0.225       |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.351        |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 54.6     |\n",
      "|    ep_rew_mean     | -103     |\n",
      "| time/              |          |\n",
      "|    fps             | 705      |\n",
      "|    iterations      | 12       |\n",
      "|    time_elapsed    | 418      |\n",
      "|    total_timesteps | 294912   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 51.7         |\n",
      "|    ep_rew_mean          | -94.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 703          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 453          |\n",
      "|    total_timesteps      | 319488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010230638 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.138        |\n",
      "|    entropy_loss         | -11.8        |\n",
      "|    explained_variance   | 0.297        |\n",
      "|    learning_rate        | 1.35e-05     |\n",
      "|    loss                 | -0.217       |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 0.359        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 50.6         |\n",
      "|    ep_rew_mean          | -89.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 702          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 489          |\n",
      "|    total_timesteps      | 344064       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010471259 |\n",
      "|    clip_fraction        | 0.00193      |\n",
      "|    clip_range           | 0.138        |\n",
      "|    entropy_loss         | -11.8        |\n",
      "|    explained_variance   | 0.303        |\n",
      "|    learning_rate        | 1.35e-05     |\n",
      "|    loss                 | -0.209       |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 0.366        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 50.6         |\n",
      "|    ep_rew_mean          | -96          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 700          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 526          |\n",
      "|    total_timesteps      | 368640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012686569 |\n",
      "|    clip_fraction        | 0.00374      |\n",
      "|    clip_range           | 0.138        |\n",
      "|    entropy_loss         | -11.9        |\n",
      "|    explained_variance   | 0.302        |\n",
      "|    learning_rate        | 1.35e-05     |\n",
      "|    loss                 | -0.226       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 0.358        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 52.3         |\n",
      "|    ep_rew_mean          | -95.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 699          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 561          |\n",
      "|    total_timesteps      | 393216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014911414 |\n",
      "|    clip_fraction        | 0.00699      |\n",
      "|    clip_range           | 0.138        |\n",
      "|    entropy_loss         | -11.9        |\n",
      "|    explained_variance   | 0.286        |\n",
      "|    learning_rate        | 1.35e-05     |\n",
      "|    loss                 | -0.247       |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 0.351        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 50.2         |\n",
      "|    ep_rew_mean          | -95.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 699          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 596          |\n",
      "|    total_timesteps      | 417792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014124733 |\n",
      "|    clip_fraction        | 0.00479      |\n",
      "|    clip_range           | 0.138        |\n",
      "|    entropy_loss         | -11.9        |\n",
      "|    explained_variance   | 0.314        |\n",
      "|    learning_rate        | 1.35e-05     |\n",
      "|    loss                 | -0.224       |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 0.348        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 48.1         |\n",
      "|    ep_rew_mean          | -89.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 698          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 633          |\n",
      "|    total_timesteps      | 442368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016897834 |\n",
      "|    clip_fraction        | 0.00838      |\n",
      "|    clip_range           | 0.138        |\n",
      "|    entropy_loss         | -12          |\n",
      "|    explained_variance   | 0.3          |\n",
      "|    learning_rate        | 1.35e-05     |\n",
      "|    loss                 | -0.229       |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 0.349        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 52.4        |\n",
      "|    ep_rew_mean          | -106        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 697         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 669         |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001417617 |\n",
      "|    clip_fraction        | 0.00503     |\n",
      "|    clip_range           | 0.138       |\n",
      "|    entropy_loss         | -12         |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 1.35e-05    |\n",
      "|    loss                 | -0.236      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00243    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.344       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 48.8         |\n",
      "|    ep_rew_mean          | -93.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 698          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 704          |\n",
      "|    total_timesteps      | 491520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015224545 |\n",
      "|    clip_fraction        | 0.00553      |\n",
      "|    clip_range           | 0.138        |\n",
      "|    entropy_loss         | -12          |\n",
      "|    explained_variance   | 0.331        |\n",
      "|    learning_rate        | 1.35e-05     |\n",
      "|    loss                 | -0.213       |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 0.353        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 44.4         |\n",
      "|    ep_rew_mean          | -81.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 697          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 740          |\n",
      "|    total_timesteps      | 516096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018326187 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.138        |\n",
      "|    entropy_loss         | -12.1        |\n",
      "|    explained_variance   | 0.339        |\n",
      "|    learning_rate        | 1.35e-05     |\n",
      "|    loss                 | -0.217       |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 0.344        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 45.8         |\n",
      "|    ep_rew_mean          | -88.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 697          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 775          |\n",
      "|    total_timesteps      | 540672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014699056 |\n",
      "|    clip_fraction        | 0.00582      |\n",
      "|    clip_range           | 0.138        |\n",
      "|    entropy_loss         | -12.1        |\n",
      "|    explained_variance   | 0.334        |\n",
      "|    learning_rate        | 1.35e-05     |\n",
      "|    loss                 | -0.202       |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 0.375        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=163.62 +/- 47.18\n",
      "Episode length: 149.80 +/- 75.71\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 150          |\n",
      "|    mean_reward          | 164          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 560000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017148281 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.138        |\n",
      "|    entropy_loss         | -12.2        |\n",
      "|    explained_variance   | 0.327        |\n",
      "|    learning_rate        | 1.35e-05     |\n",
      "|    loss                 | -0.24        |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 0.353        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 41.4     |\n",
      "|    ep_rew_mean     | -79.1    |\n",
      "| time/              |          |\n",
      "|    fps             | 696      |\n",
      "|    iterations      | 23       |\n",
      "|    time_elapsed    | 811      |\n",
      "|    total_timesteps | 565248   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 37.7         |\n",
      "|    ep_rew_mean          | -73          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 695          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 847          |\n",
      "|    total_timesteps      | 589824       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019858691 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.138        |\n",
      "|    entropy_loss         | -12.2        |\n",
      "|    explained_variance   | 0.325        |\n",
      "|    learning_rate        | 1.35e-05     |\n",
      "|    loss                 | -0.199       |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 0.341        |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Training del modello\n",
    "model = PPO(**model_params)\n",
    "model.learn(total_timesteps=1_000_000, callback=CallbackList([eval_callback, checkpoint_callback]))\n",
    "\n",
    "# Salvataggio del modello e della normalizzazione\n",
    "model.save(\"ppo_Ant_model\")\n",
    "env.save(\"vecnormalize_Ant.pkl\")\n",
    "\n",
    "# Funzione di valutazione migliorata\n",
    "def evaluate_agent(model, env, episodes=100):\n",
    "    mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=episodes, deterministic=True)\n",
    "    print(f\"Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n",
    "    return mean_reward, std_reward\n",
    "\n",
    "# Valutiamo il modello addestrato\n",
    "mean_reward_trained, std_reward_trained = evaluate_agent(model, env, episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Salviamo il modello\n",
    "model.save(\"ppo_Ant_model\")\n",
    "env.save(\"vecnormalize_Ant.pkl\")  # salviamo anche i parametri di normalizzazione\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
