{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import time\n",
    "\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, VecNormalize, DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback, CallbackList\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to ./sac_HalfCheetah_tensorboard/SAC_2\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -256     |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 82       |\n",
      "|    time_elapsed    | 48       |\n",
      "|    total_timesteps | 4000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.5      |\n",
      "|    critic_loss     | 0.03     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 7792     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -78.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 93       |\n",
      "|    total_timesteps | 8000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.09    |\n",
      "|    critic_loss     | 0.283    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 15792    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 118      |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 138      |\n",
      "|    total_timesteps | 12000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.7    |\n",
      "|    critic_loss     | 0.401    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 23792    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 119      |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 184      |\n",
      "|    total_timesteps | 16000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -25.9    |\n",
      "|    critic_loss     | 0.414    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 31792    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=684.91 +/- 91.27\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 685      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 20000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -29.1    |\n",
      "|    critic_loss     | 0.468    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 39792    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 221      |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 232      |\n",
      "|    total_timesteps | 20000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 318      |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 278      |\n",
      "|    total_timesteps | 24000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -36.2    |\n",
      "|    critic_loss     | 0.429    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 47792    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 391      |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 324      |\n",
      "|    total_timesteps | 28000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -40.1    |\n",
      "|    critic_loss     | 0.424    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 55792    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 454      |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 371      |\n",
      "|    total_timesteps | 32000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -43.7    |\n",
      "|    critic_loss     | 0.369    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 63792    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 510      |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 418      |\n",
      "|    total_timesteps | 36000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -47.2    |\n",
      "|    critic_loss     | 0.348    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 71792    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=757.84 +/- 565.77\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 758      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 40000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -51.4    |\n",
      "|    critic_loss     | 0.428    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 79792    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 575      |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 466      |\n",
      "|    total_timesteps | 40000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 634      |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 514      |\n",
      "|    total_timesteps | 44000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -57.1    |\n",
      "|    critic_loss     | 0.517    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 87792    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 687      |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 560      |\n",
      "|    total_timesteps | 48000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -62.3    |\n",
      "|    critic_loss     | 0.728    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 95792    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 721      |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 607      |\n",
      "|    total_timesteps | 52000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -62.7    |\n",
      "|    critic_loss     | 0.767    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 103792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 777      |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 653      |\n",
      "|    total_timesteps | 56000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -67      |\n",
      "|    critic_loss     | 0.856    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 111792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=1451.06 +/- 180.66\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 1.45e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 60000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -66.8    |\n",
      "|    critic_loss     | 1.03     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 119792   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 802      |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 701      |\n",
      "|    total_timesteps | 60000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 826      |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 749      |\n",
      "|    total_timesteps | 64000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -68.5    |\n",
      "|    critic_loss     | 0.997    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 127792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 868      |\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 794      |\n",
      "|    total_timesteps | 68000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -71.3    |\n",
      "|    critic_loss     | 1.08     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 135792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 913      |\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 840      |\n",
      "|    total_timesteps | 72000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -76.3    |\n",
      "|    critic_loss     | 0.923    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 143792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 955      |\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 887      |\n",
      "|    total_timesteps | 76000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -81.4    |\n",
      "|    critic_loss     | 1.1      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 151792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=1677.14 +/- 50.52\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 1.68e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 80000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -84.1    |\n",
      "|    critic_loss     | 1.15     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 159792   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 996      |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 933      |\n",
      "|    total_timesteps | 80000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.04e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 980      |\n",
      "|    total_timesteps | 84000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -88.7    |\n",
      "|    critic_loss     | 1.2      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 167792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.08e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1027     |\n",
      "|    total_timesteps | 88000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93      |\n",
      "|    critic_loss     | 1.32     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 175792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.12e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1073     |\n",
      "|    total_timesteps | 92000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96      |\n",
      "|    critic_loss     | 1.6      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 183792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.15e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1119     |\n",
      "|    total_timesteps | 96000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.1    |\n",
      "|    critic_loss     | 1.55     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 191792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=2121.35 +/- 37.95\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.12e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 100000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 1.78     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 199792   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.19e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1165     |\n",
      "|    total_timesteps | 100000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.28e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 104      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1211     |\n",
      "|    total_timesteps | 104000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 1.71     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 207792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.36e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 108      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1258     |\n",
      "|    total_timesteps | 108000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 1.85     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 215792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.42e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 112      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1304     |\n",
      "|    total_timesteps | 112000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -108     |\n",
      "|    critic_loss     | 1.68     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 223792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.51e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 116      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1350     |\n",
      "|    total_timesteps | 116000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -113     |\n",
      "|    critic_loss     | 1.73     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 231792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-1017.29 +/- 63.19\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/              |           |\n",
      "|    mean_ep_length  | 1e+03     |\n",
      "|    mean_reward     | -1.02e+03 |\n",
      "| time/              |           |\n",
      "|    total_timesteps | 120000    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -164      |\n",
      "|    critic_loss     | 4.91      |\n",
      "|    ent_coef        | 0.001     |\n",
      "|    learning_rate   | 4.35e-05  |\n",
      "|    n_updates       | 239792    |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.54e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1396     |\n",
      "|    total_timesteps | 120000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.49e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 124      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1442     |\n",
      "|    total_timesteps | 124000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -131     |\n",
      "|    critic_loss     | 3.13     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 247792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.54e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 128      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 1487     |\n",
      "|    total_timesteps | 128000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -110     |\n",
      "|    critic_loss     | 2.5      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 255792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.6e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 132      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 1533     |\n",
      "|    total_timesteps | 132000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -109     |\n",
      "|    critic_loss     | 2.36     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 263792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.66e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 136      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 1579     |\n",
      "|    total_timesteps | 136000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -111     |\n",
      "|    critic_loss     | 2.04     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 271792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=2336.95 +/- 81.64\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.34e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 140000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -116     |\n",
      "|    critic_loss     | 2.45     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 279792   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.72e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 1626     |\n",
      "|    total_timesteps | 140000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.77e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 144      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 1673     |\n",
      "|    total_timesteps | 144000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -117     |\n",
      "|    critic_loss     | 2.12     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 287792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.82e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 148      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1720     |\n",
      "|    total_timesteps | 148000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -121     |\n",
      "|    critic_loss     | 2.04     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 295792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.87e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 152      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 1767     |\n",
      "|    total_timesteps | 152000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -124     |\n",
      "|    critic_loss     | 2.02     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 303792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.92e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 156      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1814     |\n",
      "|    total_timesteps | 156000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -127     |\n",
      "|    critic_loss     | 1.7      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 311792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=2655.41 +/- 9.79\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.66e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 160000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -129     |\n",
      "|    critic_loss     | 1.91     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 319792   |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.97e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 160      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1863     |\n",
      "|    total_timesteps | 160000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.01e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 164      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1911     |\n",
      "|    total_timesteps | 164000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -167     |\n",
      "|    critic_loss     | 8.71     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 327792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.91e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 168      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 1958     |\n",
      "|    total_timesteps | 168000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -348     |\n",
      "|    critic_loss     | 3.41e+03 |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 335792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.81e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 172      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2004     |\n",
      "|    total_timesteps | 172000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -989     |\n",
      "|    critic_loss     | 2.37e+03 |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 343792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.7e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 176      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2051     |\n",
      "|    total_timesteps | 176000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -831     |\n",
      "|    critic_loss     | 3.11e+03 |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 351792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=-359.08 +/- 21.10\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -359     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 180000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -591     |\n",
      "|    critic_loss     | 1.11e+03 |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 359792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 180      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2098     |\n",
      "|    total_timesteps | 180000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.52e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 184      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2144     |\n",
      "|    total_timesteps | 184000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -332     |\n",
      "|    critic_loss     | 479      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 367792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.42e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 188      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2190     |\n",
      "|    total_timesteps | 188000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -231     |\n",
      "|    critic_loss     | 523      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 375792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.32e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 192      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2235     |\n",
      "|    total_timesteps | 192000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -170     |\n",
      "|    critic_loss     | 701      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 383792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.22e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 196      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2281     |\n",
      "|    total_timesteps | 196000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -186     |\n",
      "|    critic_loss     | 170      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 391792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=-147.90 +/- 371.29\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -148     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 200000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -148     |\n",
      "|    critic_loss     | 238      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 399792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.11e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2328     |\n",
      "|    total_timesteps | 200000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.04e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 204      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2374     |\n",
      "|    total_timesteps | 204000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -139     |\n",
      "|    critic_loss     | 153      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 407792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 952      |\n",
      "| time/              |          |\n",
      "|    episodes        | 208      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2420     |\n",
      "|    total_timesteps | 208000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -123     |\n",
      "|    critic_loss     | 394      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 415792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 858      |\n",
      "| time/              |          |\n",
      "|    episodes        | 212      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2467     |\n",
      "|    total_timesteps | 212000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -120     |\n",
      "|    critic_loss     | 149      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 423792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 750      |\n",
      "| time/              |          |\n",
      "|    episodes        | 216      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2515     |\n",
      "|    total_timesteps | 216000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -118     |\n",
      "|    critic_loss     | 232      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 431792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=-563.50 +/- 26.46\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -563     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 220000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -123     |\n",
      "|    critic_loss     | 134      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 439792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 672      |\n",
      "| time/              |          |\n",
      "|    episodes        | 220      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2563     |\n",
      "|    total_timesteps | 220000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 676      |\n",
      "| time/              |          |\n",
      "|    episodes        | 224      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2610     |\n",
      "|    total_timesteps | 224000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 387      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 447792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 581      |\n",
      "| time/              |          |\n",
      "|    episodes        | 228      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2656     |\n",
      "|    total_timesteps | 228000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 175      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 455792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 488      |\n",
      "| time/              |          |\n",
      "|    episodes        | 232      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2703     |\n",
      "|    total_timesteps | 232000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.6    |\n",
      "|    critic_loss     | 342      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 463792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 377      |\n",
      "| time/              |          |\n",
      "|    episodes        | 236      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2749     |\n",
      "|    total_timesteps | 236000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.7    |\n",
      "|    critic_loss     | 482      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 471792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=-372.17 +/- 300.43\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -372     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 240000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -89.6    |\n",
      "|    critic_loss     | 107      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 479792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 260      |\n",
      "| time/              |          |\n",
      "|    episodes        | 240      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2797     |\n",
      "|    total_timesteps | 240000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 155      |\n",
      "| time/              |          |\n",
      "|    episodes        | 244      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2844     |\n",
      "|    total_timesteps | 244000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -80.2    |\n",
      "|    critic_loss     | 195      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 487792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 46.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 248      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2891     |\n",
      "|    total_timesteps | 248000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -82.2    |\n",
      "|    critic_loss     | 261      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 495792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -53.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 252      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2936     |\n",
      "|    total_timesteps | 252000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -78      |\n",
      "|    critic_loss     | 104      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 503792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -160     |\n",
      "| time/              |          |\n",
      "|    episodes        | 256      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 2981     |\n",
      "|    total_timesteps | 256000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -77.8    |\n",
      "|    critic_loss     | 146      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 511792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=214.58 +/- 173.21\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 215      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 260000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -71      |\n",
      "|    critic_loss     | 148      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 519792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -266     |\n",
      "| time/              |          |\n",
      "|    episodes        | 260      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 3027     |\n",
      "|    total_timesteps | 260000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -336     |\n",
      "| time/              |          |\n",
      "|    episodes        | 264      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 3073     |\n",
      "|    total_timesteps | 264000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -66.3    |\n",
      "|    critic_loss     | 48.3     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 527792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -295     |\n",
      "| time/              |          |\n",
      "|    episodes        | 268      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 3118     |\n",
      "|    total_timesteps | 268000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -68.8    |\n",
      "|    critic_loss     | 208      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 535792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -231     |\n",
      "| time/              |          |\n",
      "|    episodes        | 272      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 3163     |\n",
      "|    total_timesteps | 272000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -71.7    |\n",
      "|    critic_loss     | 118      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 543792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -152     |\n",
      "| time/              |          |\n",
      "|    episodes        | 276      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3208     |\n",
      "|    total_timesteps | 276000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -69.1    |\n",
      "|    critic_loss     | 118      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 551792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=1370.32 +/- 56.34\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 1.37e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 280000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -67      |\n",
      "|    critic_loss     | 46.6     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 559792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -89      |\n",
      "| time/              |          |\n",
      "|    episodes        | 280      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3254     |\n",
      "|    total_timesteps | 280000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -26.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 284      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3299     |\n",
      "|    total_timesteps | 284000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -73.5    |\n",
      "|    critic_loss     | 137      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 567792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 49.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 288      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3344     |\n",
      "|    total_timesteps | 288000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -71.1    |\n",
      "|    critic_loss     | 120      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 575792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 121      |\n",
      "| time/              |          |\n",
      "|    episodes        | 292      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3389     |\n",
      "|    total_timesteps | 292000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -71.8    |\n",
      "|    critic_loss     | 79.6     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 583792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 199      |\n",
      "| time/              |          |\n",
      "|    episodes        | 296      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3434     |\n",
      "|    total_timesteps | 296000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -73      |\n",
      "|    critic_loss     | 155      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 591792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=2419.69 +/- 120.28\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.42e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 300000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -73.6    |\n",
      "|    critic_loss     | 35.5     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 599792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 289      |\n",
      "| time/              |          |\n",
      "|    episodes        | 300      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3480     |\n",
      "|    total_timesteps | 300000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 359      |\n",
      "| time/              |          |\n",
      "|    episodes        | 304      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3526     |\n",
      "|    total_timesteps | 304000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -72.9    |\n",
      "|    critic_loss     | 64       |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 607792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 407      |\n",
      "| time/              |          |\n",
      "|    episodes        | 308      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3571     |\n",
      "|    total_timesteps | 308000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -71.8    |\n",
      "|    critic_loss     | 214      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 615792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 476      |\n",
      "| time/              |          |\n",
      "|    episodes        | 312      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3616     |\n",
      "|    total_timesteps | 312000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -68      |\n",
      "|    critic_loss     | 388      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 623792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 571      |\n",
      "| time/              |          |\n",
      "|    episodes        | 316      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3661     |\n",
      "|    total_timesteps | 316000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -64.9    |\n",
      "|    critic_loss     | 56.7     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 631792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=1932.85 +/- 77.51\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 1.93e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 320000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -68.3    |\n",
      "|    critic_loss     | 28.7     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 639792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 646      |\n",
      "| time/              |          |\n",
      "|    episodes        | 320      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3707     |\n",
      "|    total_timesteps | 320000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 738      |\n",
      "| time/              |          |\n",
      "|    episodes        | 324      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3753     |\n",
      "|    total_timesteps | 324000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -75      |\n",
      "|    critic_loss     | 36.5     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 647792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 829      |\n",
      "| time/              |          |\n",
      "|    episodes        | 328      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3798     |\n",
      "|    total_timesteps | 328000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -75.6    |\n",
      "|    critic_loss     | 73.9     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 655792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 908      |\n",
      "| time/              |          |\n",
      "|    episodes        | 332      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3843     |\n",
      "|    total_timesteps | 332000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -77.1    |\n",
      "|    critic_loss     | 8.97     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 663792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1e+03    |\n",
      "| time/              |          |\n",
      "|    episodes        | 336      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3887     |\n",
      "|    total_timesteps | 336000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -76.7    |\n",
      "|    critic_loss     | 118      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 671792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=2359.70 +/- 129.68\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.36e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 340000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -79.8    |\n",
      "|    critic_loss     | 367      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 679792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.1e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 340      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3933     |\n",
      "|    total_timesteps | 340000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.18e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 344      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 3979     |\n",
      "|    total_timesteps | 344000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -79.7    |\n",
      "|    critic_loss     | 6.45     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 687792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.27e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 348      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4024     |\n",
      "|    total_timesteps | 348000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -81.6    |\n",
      "|    critic_loss     | 68.5     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 695792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.35e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 352      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4069     |\n",
      "|    total_timesteps | 352000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -78.6    |\n",
      "|    critic_loss     | 58.6     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 703792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.43e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 356      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4114     |\n",
      "|    total_timesteps | 356000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -77.5    |\n",
      "|    critic_loss     | 140      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 711792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=2015.70 +/- 50.56\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.02e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 360000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -83.3    |\n",
      "|    critic_loss     | 229      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 719792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.51e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 360      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4160     |\n",
      "|    total_timesteps | 360000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.58e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 364      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4205     |\n",
      "|    total_timesteps | 364000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -80.5    |\n",
      "|    critic_loss     | 187      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 727792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.66e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 368      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4250     |\n",
      "|    total_timesteps | 368000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -84.5    |\n",
      "|    critic_loss     | 8.43     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 735792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.72e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 372      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4295     |\n",
      "|    total_timesteps | 372000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -85.5    |\n",
      "|    critic_loss     | 15.6     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 743792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.77e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 376      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4340     |\n",
      "|    total_timesteps | 376000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -84.2    |\n",
      "|    critic_loss     | 7.04     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 751792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=2511.67 +/- 39.44\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.51e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 380000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -84.9    |\n",
      "|    critic_loss     | 32.1     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 759792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.82e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 380      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4386     |\n",
      "|    total_timesteps | 380000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.86e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 384      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4432     |\n",
      "|    total_timesteps | 384000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -85.1    |\n",
      "|    critic_loss     | 98       |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 767792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.9e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 388      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4477     |\n",
      "|    total_timesteps | 388000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -83.4    |\n",
      "|    critic_loss     | 126      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 775792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.94e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 392      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4522     |\n",
      "|    total_timesteps | 392000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -89      |\n",
      "|    critic_loss     | 6.03     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 783792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.98e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 396      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4567     |\n",
      "|    total_timesteps | 396000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -89.1    |\n",
      "|    critic_loss     | 15.2     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 791792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=2424.00 +/- 33.23\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.42e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 400000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -90.8    |\n",
      "|    critic_loss     | 214      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 799792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2e+03    |\n",
      "| time/              |          |\n",
      "|    episodes        | 400      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4613     |\n",
      "|    total_timesteps | 400000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.02e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 404      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4658     |\n",
      "|    total_timesteps | 404000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -87      |\n",
      "|    critic_loss     | 188      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 807792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.07e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 408      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4703     |\n",
      "|    total_timesteps | 408000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.9    |\n",
      "|    critic_loss     | 26.5     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 815792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.09e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 412      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4748     |\n",
      "|    total_timesteps | 412000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.4    |\n",
      "|    critic_loss     | 55       |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 823792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.11e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 416      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4793     |\n",
      "|    total_timesteps | 416000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.1    |\n",
      "|    critic_loss     | 98.1     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 831792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=420000, episode_reward=2485.44 +/- 114.24\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.49e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 420000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93      |\n",
      "|    critic_loss     | 109      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 839792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.15e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 420      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4839     |\n",
      "|    total_timesteps | 420000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.16e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 424      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4885     |\n",
      "|    total_timesteps | 424000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.6    |\n",
      "|    critic_loss     | 5.61     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 847792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.18e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 428      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4930     |\n",
      "|    total_timesteps | 428000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.8    |\n",
      "|    critic_loss     | 171      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 855792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.17e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 432      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 4975     |\n",
      "|    total_timesteps | 432000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.2    |\n",
      "|    critic_loss     | 41.5     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 863792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.19e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 436      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5020     |\n",
      "|    total_timesteps | 436000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98      |\n",
      "|    critic_loss     | 67.2     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 871792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=2341.76 +/- 94.75\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.34e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 440000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.2    |\n",
      "|    critic_loss     | 4.84     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 879792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.2e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 440      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5066     |\n",
      "|    total_timesteps | 440000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.22e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 444      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5112     |\n",
      "|    total_timesteps | 444000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.6    |\n",
      "|    critic_loss     | 64.8     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 887792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.24e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 448      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5157     |\n",
      "|    total_timesteps | 448000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.6    |\n",
      "|    critic_loss     | 31.2     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 895792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.27e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 452      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5202     |\n",
      "|    total_timesteps | 452000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 146      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 903792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.29e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 456      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5247     |\n",
      "|    total_timesteps | 456000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99      |\n",
      "|    critic_loss     | 159      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 911792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=460000, episode_reward=2508.74 +/- 109.03\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.51e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 460000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 66.2     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 919792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.31e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 460      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5292     |\n",
      "|    total_timesteps | 460000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.33e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 464      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5338     |\n",
      "|    total_timesteps | 464000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 4.9      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 927792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.35e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 468      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5383     |\n",
      "|    total_timesteps | 468000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -108     |\n",
      "|    critic_loss     | 137      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 935792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.37e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 472      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5428     |\n",
      "|    total_timesteps | 472000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 92.1     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 943792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.38e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 476      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5473     |\n",
      "|    total_timesteps | 476000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 25.3     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 951792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=2560.85 +/- 39.05\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.56e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 480000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -109     |\n",
      "|    critic_loss     | 4.13     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 959792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.39e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 480      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5519     |\n",
      "|    total_timesteps | 480000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.41e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 484      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5565     |\n",
      "|    total_timesteps | 484000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 70.4     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 967792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.42e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 488      |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 5610     |\n",
      "|    total_timesteps | 488000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -109     |\n",
      "|    critic_loss     | 92.2     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 975792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.42e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 492      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 5655     |\n",
      "|    total_timesteps | 492000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -108     |\n",
      "|    critic_loss     | 49.4     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 983792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.43e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 496      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 5700     |\n",
      "|    total_timesteps | 496000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -110     |\n",
      "|    critic_loss     | 47.2     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 991792   |\n",
      "---------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=2570.53 +/- 47.58\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.57e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 500000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -112     |\n",
      "|    critic_loss     | 4.44     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 999792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.44e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 500      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 5746     |\n",
      "|    total_timesteps | 500000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.45e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 504      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 5791     |\n",
      "|    total_timesteps | 504000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -113     |\n",
      "|    critic_loss     | 5.13     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1007792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.46e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 508      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 5836     |\n",
      "|    total_timesteps | 508000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -113     |\n",
      "|    critic_loss     | 28.1     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1015792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.48e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 512      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 5881     |\n",
      "|    total_timesteps | 512000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -112     |\n",
      "|    critic_loss     | 30.8     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1023792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.49e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 516      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 5926     |\n",
      "|    total_timesteps | 516000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -112     |\n",
      "|    critic_loss     | 134      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1031792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=520000, episode_reward=2498.72 +/- 98.98\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.5e+03  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 520000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -113     |\n",
      "|    critic_loss     | 10.6     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1039792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.5e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 520      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 5972     |\n",
      "|    total_timesteps | 520000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.51e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 524      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6019     |\n",
      "|    total_timesteps | 524000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -120     |\n",
      "|    critic_loss     | 231      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1047792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.51e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 528      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6064     |\n",
      "|    total_timesteps | 528000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -118     |\n",
      "|    critic_loss     | 52.7     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1055792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.54e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 532      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6109     |\n",
      "|    total_timesteps | 532000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -121     |\n",
      "|    critic_loss     | 50.8     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1063792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.55e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 536      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6154     |\n",
      "|    total_timesteps | 536000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -118     |\n",
      "|    critic_loss     | 120      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1071792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=540000, episode_reward=2568.55 +/- 30.53\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.57e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 540000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -121     |\n",
      "|    critic_loss     | 46.8     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1079792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.56e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 540      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6200     |\n",
      "|    total_timesteps | 540000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.56e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 544      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6245     |\n",
      "|    total_timesteps | 544000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -124     |\n",
      "|    critic_loss     | 4.87     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1087792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.56e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 548      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6290     |\n",
      "|    total_timesteps | 548000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -121     |\n",
      "|    critic_loss     | 5.19     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1095792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.57e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 552      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6335     |\n",
      "|    total_timesteps | 552000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -124     |\n",
      "|    critic_loss     | 81.4     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1103792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.57e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 556      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6380     |\n",
      "|    total_timesteps | 556000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -121     |\n",
      "|    critic_loss     | 75.6     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1111792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=2586.95 +/- 38.60\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.59e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 560000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -127     |\n",
      "|    critic_loss     | 65.1     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1119792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.57e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 560      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6426     |\n",
      "|    total_timesteps | 560000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.57e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 564      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6472     |\n",
      "|    total_timesteps | 564000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -129     |\n",
      "|    critic_loss     | 4.4      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1127792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.57e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 568      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6517     |\n",
      "|    total_timesteps | 568000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -129     |\n",
      "|    critic_loss     | 67.6     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1135792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.57e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 572      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6562     |\n",
      "|    total_timesteps | 572000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -128     |\n",
      "|    critic_loss     | 70.7     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1143792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.57e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 576      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6607     |\n",
      "|    total_timesteps | 576000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -129     |\n",
      "|    critic_loss     | 3.74     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1151792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=580000, episode_reward=2558.62 +/- 36.70\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.56e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 580000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -130     |\n",
      "|    critic_loss     | 23.9     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1159792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.57e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 580      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6653     |\n",
      "|    total_timesteps | 580000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.57e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 584      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6698     |\n",
      "|    total_timesteps | 584000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -132     |\n",
      "|    critic_loss     | 75.5     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1167792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.58e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 588      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6743     |\n",
      "|    total_timesteps | 588000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -127     |\n",
      "|    critic_loss     | 392      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1175792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.58e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 592      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6788     |\n",
      "|    total_timesteps | 592000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -131     |\n",
      "|    critic_loss     | 71.5     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1183792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.59e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 596      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6833     |\n",
      "|    total_timesteps | 596000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -128     |\n",
      "|    critic_loss     | 159      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1191792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=2605.93 +/- 43.71\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 600000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -131     |\n",
      "|    critic_loss     | 10.4     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1199792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.59e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 600      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6879     |\n",
      "|    total_timesteps | 600000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.59e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 604      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6925     |\n",
      "|    total_timesteps | 604000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -130     |\n",
      "|    critic_loss     | 22.6     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1207792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.59e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 608      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 6969     |\n",
      "|    total_timesteps | 608000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -130     |\n",
      "|    critic_loss     | 51.9     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1215792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.59e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 612      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7015     |\n",
      "|    total_timesteps | 612000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -132     |\n",
      "|    critic_loss     | 4.89     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1223792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.6e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 616      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7059     |\n",
      "|    total_timesteps | 616000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -132     |\n",
      "|    critic_loss     | 28.8     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1231792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=620000, episode_reward=2627.23 +/- 55.72\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.63e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 620000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -135     |\n",
      "|    critic_loss     | 46.9     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1239792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.6e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 620      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7106     |\n",
      "|    total_timesteps | 620000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.6e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 624      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7151     |\n",
      "|    total_timesteps | 624000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -129     |\n",
      "|    critic_loss     | 20.4     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1247792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 628      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7196     |\n",
      "|    total_timesteps | 628000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -130     |\n",
      "|    critic_loss     | 127      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1255792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 632      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7241     |\n",
      "|    total_timesteps | 632000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -133     |\n",
      "|    critic_loss     | 91.9     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1263792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 636      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7286     |\n",
      "|    total_timesteps | 636000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -135     |\n",
      "|    critic_loss     | 3.37     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1271792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=2538.10 +/- 205.77\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.54e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 640000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -134     |\n",
      "|    critic_loss     | 29.7     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1279792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 640      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7334     |\n",
      "|    total_timesteps | 640000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.62e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 644      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7379     |\n",
      "|    total_timesteps | 644000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -137     |\n",
      "|    critic_loss     | 5.29     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1287792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.62e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 648      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7425     |\n",
      "|    total_timesteps | 648000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -133     |\n",
      "|    critic_loss     | 77.9     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1295792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.62e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 652      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7470     |\n",
      "|    total_timesteps | 652000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -131     |\n",
      "|    critic_loss     | 178      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1303792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.62e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 656      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7515     |\n",
      "|    total_timesteps | 656000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -134     |\n",
      "|    critic_loss     | 52.5     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1311792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=660000, episode_reward=2637.67 +/- 54.26\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.64e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 660000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -135     |\n",
      "|    critic_loss     | 112      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1319792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.63e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 660      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7561     |\n",
      "|    total_timesteps | 660000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.63e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 664      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7606     |\n",
      "|    total_timesteps | 664000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -135     |\n",
      "|    critic_loss     | 3.62     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1327792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.63e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 668      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7651     |\n",
      "|    total_timesteps | 668000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -138     |\n",
      "|    critic_loss     | 3.2      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1335792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.63e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 672      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7696     |\n",
      "|    total_timesteps | 672000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -139     |\n",
      "|    critic_loss     | 113      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1343792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.63e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 676      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7741     |\n",
      "|    total_timesteps | 676000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -140     |\n",
      "|    critic_loss     | 2.5      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1351792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=680000, episode_reward=-84.03 +/- 58.44\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | -84      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 680000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -142     |\n",
      "|    critic_loss     | 2.07     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1359792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.63e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 680      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7787     |\n",
      "|    total_timesteps | 680000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.64e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 684      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7833     |\n",
      "|    total_timesteps | 684000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -146     |\n",
      "|    critic_loss     | 2.23     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1367792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.64e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 688      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7878     |\n",
      "|    total_timesteps | 688000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -147     |\n",
      "|    critic_loss     | 2.88     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1375792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.64e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 692      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7923     |\n",
      "|    total_timesteps | 692000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -147     |\n",
      "|    critic_loss     | 2.07     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1383792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.65e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 696      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 7967     |\n",
      "|    total_timesteps | 696000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -148     |\n",
      "|    critic_loss     | 2.08     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1391792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=2708.97 +/- 32.99\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.71e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 700000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -149     |\n",
      "|    critic_loss     | 1.96     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1399792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.65e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 700      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8013     |\n",
      "|    total_timesteps | 700000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.65e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 704      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8059     |\n",
      "|    total_timesteps | 704000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -152     |\n",
      "|    critic_loss     | 1.73     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1407792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.66e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 708      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8104     |\n",
      "|    total_timesteps | 708000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -152     |\n",
      "|    critic_loss     | 1.75     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1415792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.63e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 712      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8149     |\n",
      "|    total_timesteps | 712000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -150     |\n",
      "|    critic_loss     | 1.53     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1423792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.63e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 716      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8194     |\n",
      "|    total_timesteps | 716000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -151     |\n",
      "|    critic_loss     | 2.01     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1431792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=720000, episode_reward=2745.63 +/- 15.29\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.75e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 720000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -154     |\n",
      "|    critic_loss     | 1.73     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1439792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.64e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 720      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8239     |\n",
      "|    total_timesteps | 720000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 724      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8285     |\n",
      "|    total_timesteps | 724000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -154     |\n",
      "|    critic_loss     | 1.74     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1447792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 728      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8330     |\n",
      "|    total_timesteps | 728000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -156     |\n",
      "|    critic_loss     | 2.23     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1455792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.62e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 732      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8375     |\n",
      "|    total_timesteps | 732000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -156     |\n",
      "|    critic_loss     | 1.91     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1463792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.62e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 736      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8420     |\n",
      "|    total_timesteps | 736000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -158     |\n",
      "|    critic_loss     | 1.72     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1471792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=740000, episode_reward=156.15 +/- 4.79\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 156      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 740000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -159     |\n",
      "|    critic_loss     | 2.04     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1479792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.62e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 740      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8466     |\n",
      "|    total_timesteps | 740000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.63e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 744      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8512     |\n",
      "|    total_timesteps | 744000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -162     |\n",
      "|    critic_loss     | 1.43     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1487792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.63e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 748      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8557     |\n",
      "|    total_timesteps | 748000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -161     |\n",
      "|    critic_loss     | 1.83     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1495792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.64e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 752      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8601     |\n",
      "|    total_timesteps | 752000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -163     |\n",
      "|    critic_loss     | 1.29     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1503792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.63e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 756      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8646     |\n",
      "|    total_timesteps | 756000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -164     |\n",
      "|    critic_loss     | 1.15     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1511792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=760000, episode_reward=2740.49 +/- 18.96\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.74e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 760000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -166     |\n",
      "|    critic_loss     | 1.23     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1519792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.64e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 760      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8692     |\n",
      "|    total_timesteps | 760000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.64e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 764      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8738     |\n",
      "|    total_timesteps | 764000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -167     |\n",
      "|    critic_loss     | 2.4      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1527792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.62e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 768      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8783     |\n",
      "|    total_timesteps | 768000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -168     |\n",
      "|    critic_loss     | 1.36     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1535792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.6e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 772      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8828     |\n",
      "|    total_timesteps | 772000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -166     |\n",
      "|    critic_loss     | 1.51     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1543792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 776      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8872     |\n",
      "|    total_timesteps | 776000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -167     |\n",
      "|    critic_loss     | 0.889    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1551792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=780000, episode_reward=2792.40 +/- 12.88\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.79e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 780000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -167     |\n",
      "|    critic_loss     | 1.07     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1559792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 780      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8918     |\n",
      "|    total_timesteps | 780000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 784      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 8964     |\n",
      "|    total_timesteps | 784000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -169     |\n",
      "|    critic_loss     | 0.83     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1567792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 788      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9009     |\n",
      "|    total_timesteps | 788000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -168     |\n",
      "|    critic_loss     | 1.44     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1575792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 792      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9054     |\n",
      "|    total_timesteps | 792000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -167     |\n",
      "|    critic_loss     | 1.21     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1583792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 796      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9099     |\n",
      "|    total_timesteps | 796000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -168     |\n",
      "|    critic_loss     | 0.862    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1591792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=2743.32 +/- 6.28\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.74e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 800000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -169     |\n",
      "|    critic_loss     | 0.811    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1599792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 800      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9145     |\n",
      "|    total_timesteps | 800000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 804      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9190     |\n",
      "|    total_timesteps | 804000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -169     |\n",
      "|    critic_loss     | 0.84     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1607792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.61e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 808      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9235     |\n",
      "|    total_timesteps | 808000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -170     |\n",
      "|    critic_loss     | 1.24     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1615792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.65e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 812      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9280     |\n",
      "|    total_timesteps | 812000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -170     |\n",
      "|    critic_loss     | 0.805    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1623792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.65e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 816      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9325     |\n",
      "|    total_timesteps | 816000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -170     |\n",
      "|    critic_loss     | 1.14     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1631792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=820000, episode_reward=2733.12 +/- 8.37\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.73e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 820000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -171     |\n",
      "|    critic_loss     | 1.16     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1639792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.65e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 820      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9370     |\n",
      "|    total_timesteps | 820000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.68e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 824      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9416     |\n",
      "|    total_timesteps | 824000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -171     |\n",
      "|    critic_loss     | 0.755    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1647792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.68e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 828      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9461     |\n",
      "|    total_timesteps | 828000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -171     |\n",
      "|    critic_loss     | 0.738    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1655792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.68e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 832      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9506     |\n",
      "|    total_timesteps | 832000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -171     |\n",
      "|    critic_loss     | 0.801    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1663792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.68e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 836      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9551     |\n",
      "|    total_timesteps | 836000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -172     |\n",
      "|    critic_loss     | 0.778    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1671792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=840000, episode_reward=2772.89 +/- 6.19\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.77e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 840000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -173     |\n",
      "|    critic_loss     | 0.851    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1679792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.68e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 840      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9596     |\n",
      "|    total_timesteps | 840000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.69e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 844      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9642     |\n",
      "|    total_timesteps | 844000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -173     |\n",
      "|    critic_loss     | 1.17     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1687792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.68e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 848      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9687     |\n",
      "|    total_timesteps | 848000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -173     |\n",
      "|    critic_loss     | 0.633    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1695792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.68e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 852      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9732     |\n",
      "|    total_timesteps | 852000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -174     |\n",
      "|    critic_loss     | 0.851    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1703792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.69e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 856      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9777     |\n",
      "|    total_timesteps | 856000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -173     |\n",
      "|    critic_loss     | 0.446    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1711792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=860000, episode_reward=2738.21 +/- 9.28\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.74e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 860000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -174     |\n",
      "|    critic_loss     | 0.552    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1719792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.69e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 860      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9823     |\n",
      "|    total_timesteps | 860000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.69e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 864      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9868     |\n",
      "|    total_timesteps | 864000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -173     |\n",
      "|    critic_loss     | 0.461    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1727792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.71e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 868      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9913     |\n",
      "|    total_timesteps | 868000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -173     |\n",
      "|    critic_loss     | 0.908    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1735792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.74e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 872      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 9958     |\n",
      "|    total_timesteps | 872000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -174     |\n",
      "|    critic_loss     | 0.911    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1743792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.74e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 876      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10003    |\n",
      "|    total_timesteps | 876000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -174     |\n",
      "|    critic_loss     | 0.85     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1751792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=880000, episode_reward=2776.31 +/- 13.73\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.78e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 880000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -175     |\n",
      "|    critic_loss     | 0.516    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1759792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.74e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 880      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10049    |\n",
      "|    total_timesteps | 880000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.75e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 884      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10094    |\n",
      "|    total_timesteps | 884000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -175     |\n",
      "|    critic_loss     | 0.426    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1767792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.75e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 888      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10139    |\n",
      "|    total_timesteps | 888000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -175     |\n",
      "|    critic_loss     | 0.66     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1775792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.76e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 892      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10184    |\n",
      "|    total_timesteps | 892000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -175     |\n",
      "|    critic_loss     | 0.602    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1783792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.76e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 896      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10229    |\n",
      "|    total_timesteps | 896000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -175     |\n",
      "|    critic_loss     | 0.506    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1791792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=2790.96 +/- 18.55\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.79e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 900000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -176     |\n",
      "|    critic_loss     | 0.523    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1799792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.76e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 900      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10275    |\n",
      "|    total_timesteps | 900000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.77e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 904      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10320    |\n",
      "|    total_timesteps | 904000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -177     |\n",
      "|    critic_loss     | 0.348    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1807792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.77e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 908      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10365    |\n",
      "|    total_timesteps | 908000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -176     |\n",
      "|    critic_loss     | 0.408    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1815792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.77e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 912      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10410    |\n",
      "|    total_timesteps | 912000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -177     |\n",
      "|    critic_loss     | 0.461    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1823792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.77e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 916      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10455    |\n",
      "|    total_timesteps | 916000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -176     |\n",
      "|    critic_loss     | 0.681    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1831792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=920000, episode_reward=2793.97 +/- 17.38\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.79e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 920000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -177     |\n",
      "|    critic_loss     | 0.462    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1839792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.77e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 920      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10501    |\n",
      "|    total_timesteps | 920000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.78e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 924      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10546    |\n",
      "|    total_timesteps | 924000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -177     |\n",
      "|    critic_loss     | 0.339    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1847792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.78e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 928      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10591    |\n",
      "|    total_timesteps | 928000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -178     |\n",
      "|    critic_loss     | 0.239    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1855792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.78e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 932      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10636    |\n",
      "|    total_timesteps | 932000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -178     |\n",
      "|    critic_loss     | 0.344    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1863792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.78e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 936      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10681    |\n",
      "|    total_timesteps | 936000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -178     |\n",
      "|    critic_loss     | 0.383    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1871792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=940000, episode_reward=2776.28 +/- 22.48\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.78e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 940000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -178     |\n",
      "|    critic_loss     | 0.506    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1879792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.78e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 940      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10727    |\n",
      "|    total_timesteps | 940000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.78e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 944      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10773    |\n",
      "|    total_timesteps | 944000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -179     |\n",
      "|    critic_loss     | 0.277    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1887792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.78e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 948      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10818    |\n",
      "|    total_timesteps | 948000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -179     |\n",
      "|    critic_loss     | 0.248    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1895792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.78e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 952      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10863    |\n",
      "|    total_timesteps | 952000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -177     |\n",
      "|    critic_loss     | 0.458    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1903792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.79e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 956      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10908    |\n",
      "|    total_timesteps | 956000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -178     |\n",
      "|    critic_loss     | 0.36     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1911792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=960000, episode_reward=2800.17 +/- 41.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 960000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -178     |\n",
      "|    critic_loss     | 0.375    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1919792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.79e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 960      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10954    |\n",
      "|    total_timesteps | 960000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.79e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 964      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 10999    |\n",
      "|    total_timesteps | 964000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -178     |\n",
      "|    critic_loss     | 0.237    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1927792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.79e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 968      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11044    |\n",
      "|    total_timesteps | 968000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -178     |\n",
      "|    critic_loss     | 0.414    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1935792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 972      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11089    |\n",
      "|    total_timesteps | 972000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -178     |\n",
      "|    critic_loss     | 0.469    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1943792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 976      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11134    |\n",
      "|    total_timesteps | 976000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -179     |\n",
      "|    critic_loss     | 0.276    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1951792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=980000, episode_reward=2811.22 +/- 15.42\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.81e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 980000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -178     |\n",
      "|    critic_loss     | 0.553    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1959792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 980      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11183    |\n",
      "|    total_timesteps | 980000   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 984      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11228    |\n",
      "|    total_timesteps | 984000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -179     |\n",
      "|    critic_loss     | 0.295    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1967792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 988      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11275    |\n",
      "|    total_timesteps | 988000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -179     |\n",
      "|    critic_loss     | 0.344    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1975792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 992      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11322    |\n",
      "|    total_timesteps | 992000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -179     |\n",
      "|    critic_loss     | 0.3      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1983792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 996      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11369    |\n",
      "|    total_timesteps | 996000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -178     |\n",
      "|    critic_loss     | 0.551    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1991792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=2820.67 +/- 20.02\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.82e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1000000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -179     |\n",
      "|    critic_loss     | 0.374    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 1999792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 1000     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11416    |\n",
      "|    total_timesteps | 1000000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 1004     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11464    |\n",
      "|    total_timesteps | 1004000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -180     |\n",
      "|    critic_loss     | 0.228    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2007792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 1008     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11510    |\n",
      "|    total_timesteps | 1008000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -180     |\n",
      "|    critic_loss     | 0.253    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2015792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 1012     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11556    |\n",
      "|    total_timesteps | 1012000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -179     |\n",
      "|    critic_loss     | 0.324    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2023792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 1016     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11603    |\n",
      "|    total_timesteps | 1016000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -180     |\n",
      "|    critic_loss     | 0.344    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2031792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1020000, episode_reward=2822.69 +/- 13.55\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.82e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1020000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -180     |\n",
      "|    critic_loss     | 0.27     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2039792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 1020     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11650    |\n",
      "|    total_timesteps | 1020000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.81e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1024     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11697    |\n",
      "|    total_timesteps | 1024000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.295    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2047792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.81e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1028     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11743    |\n",
      "|    total_timesteps | 1028000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.154    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2055792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.81e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1032     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11790    |\n",
      "|    total_timesteps | 1032000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.339    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2063792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.81e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1036     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11836    |\n",
      "|    total_timesteps | 1036000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.262    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2071792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1040000, episode_reward=2840.88 +/- 14.02\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.84e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1040000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.285    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2079792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.81e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1040     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11883    |\n",
      "|    total_timesteps | 1040000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.82e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1044     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11930    |\n",
      "|    total_timesteps | 1044000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -182     |\n",
      "|    critic_loss     | 0.284    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2087792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.82e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1048     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11976    |\n",
      "|    total_timesteps | 1048000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.231    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2095792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.82e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1052     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12022    |\n",
      "|    total_timesteps | 1052000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.598    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2103792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.82e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1056     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12069    |\n",
      "|    total_timesteps | 1056000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -182     |\n",
      "|    critic_loss     | 0.231    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2111792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1060000, episode_reward=2843.55 +/- 32.44\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.84e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1060000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.28     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2119792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.82e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1060     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12116    |\n",
      "|    total_timesteps | 1060000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.82e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1064     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12163    |\n",
      "|    total_timesteps | 1064000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.177    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2127792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.83e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1068     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12209    |\n",
      "|    total_timesteps | 1068000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.339    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2135792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.83e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1072     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12255    |\n",
      "|    total_timesteps | 1072000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.411    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2143792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.83e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1076     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12301    |\n",
      "|    total_timesteps | 1076000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.278    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2151792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1080000, episode_reward=2868.93 +/- 15.64\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.87e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1080000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -182     |\n",
      "|    critic_loss     | 0.277    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2159792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.83e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1080     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12349    |\n",
      "|    total_timesteps | 1080000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.83e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1084     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12396    |\n",
      "|    total_timesteps | 1084000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 0.255    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2167792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.83e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1088     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12441    |\n",
      "|    total_timesteps | 1088000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -182     |\n",
      "|    critic_loss     | 0.283    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2175792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.83e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1092     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12486    |\n",
      "|    total_timesteps | 1092000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -182     |\n",
      "|    critic_loss     | 0.28     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2183792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.84e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1096     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12531    |\n",
      "|    total_timesteps | 1096000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -182     |\n",
      "|    critic_loss     | 0.492    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2191792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1100000, episode_reward=2843.34 +/- 27.39\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.84e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1100000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -182     |\n",
      "|    critic_loss     | 0.256    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2199792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.84e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1100     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12577    |\n",
      "|    total_timesteps | 1100000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.84e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1104     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12622    |\n",
      "|    total_timesteps | 1104000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -182     |\n",
      "|    critic_loss     | 0.224    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2207792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.84e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1108     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12667    |\n",
      "|    total_timesteps | 1108000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -183     |\n",
      "|    critic_loss     | 0.276    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2215792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.84e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1112     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12712    |\n",
      "|    total_timesteps | 1112000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -183     |\n",
      "|    critic_loss     | 0.236    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2223792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.84e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1116     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12757    |\n",
      "|    total_timesteps | 1116000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -182     |\n",
      "|    critic_loss     | 0.299    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2231792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1120000, episode_reward=2854.31 +/- 26.54\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.85e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1120000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -182     |\n",
      "|    critic_loss     | 0.198    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2239792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.85e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1120     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12803    |\n",
      "|    total_timesteps | 1120000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.85e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1124     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12848    |\n",
      "|    total_timesteps | 1124000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -183     |\n",
      "|    critic_loss     | 0.263    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2247792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.85e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1128     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12893    |\n",
      "|    total_timesteps | 1128000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -182     |\n",
      "|    critic_loss     | 0.25     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2255792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.85e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1132     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12938    |\n",
      "|    total_timesteps | 1132000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -183     |\n",
      "|    critic_loss     | 0.246    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2263792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.85e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1136     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 12983    |\n",
      "|    total_timesteps | 1136000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -183     |\n",
      "|    critic_loss     | 0.259    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2271792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1140000, episode_reward=2854.96 +/- 24.89\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.85e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1140000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -183     |\n",
      "|    critic_loss     | 0.24     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2279792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.85e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1140     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13029    |\n",
      "|    total_timesteps | 1140000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.85e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1144     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13075    |\n",
      "|    total_timesteps | 1144000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -183     |\n",
      "|    critic_loss     | 0.25     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2287792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.85e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1148     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13120    |\n",
      "|    total_timesteps | 1148000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -183     |\n",
      "|    critic_loss     | 0.249    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2295792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.85e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1152     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13165    |\n",
      "|    total_timesteps | 1152000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -183     |\n",
      "|    critic_loss     | 0.329    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2303792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.86e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1156     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13210    |\n",
      "|    total_timesteps | 1156000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -184     |\n",
      "|    critic_loss     | 0.15     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2311792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1160000, episode_reward=2874.34 +/- 66.63\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.87e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1160000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -184     |\n",
      "|    critic_loss     | 0.205    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2319792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.86e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1160     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13256    |\n",
      "|    total_timesteps | 1160000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.86e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1164     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13301    |\n",
      "|    total_timesteps | 1164000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -183     |\n",
      "|    critic_loss     | 0.287    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2327792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.86e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1168     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13346    |\n",
      "|    total_timesteps | 1168000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -183     |\n",
      "|    critic_loss     | 0.25     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2335792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.86e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1172     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13391    |\n",
      "|    total_timesteps | 1172000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -183     |\n",
      "|    critic_loss     | 0.281    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2343792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.86e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1176     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13436    |\n",
      "|    total_timesteps | 1176000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -184     |\n",
      "|    critic_loss     | 0.319    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2351792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1180000, episode_reward=2920.32 +/- 35.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.92e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1180000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -184     |\n",
      "|    critic_loss     | 0.275    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2359792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.87e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1180     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13482    |\n",
      "|    total_timesteps | 1180000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.87e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1184     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13528    |\n",
      "|    total_timesteps | 1184000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -184     |\n",
      "|    critic_loss     | 0.254    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2367792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.87e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1188     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13573    |\n",
      "|    total_timesteps | 1188000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -184     |\n",
      "|    critic_loss     | 0.326    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2375792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.87e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1192     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13618    |\n",
      "|    total_timesteps | 1192000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -184     |\n",
      "|    critic_loss     | 0.379    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2383792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.87e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1196     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13663    |\n",
      "|    total_timesteps | 1196000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -184     |\n",
      "|    critic_loss     | 0.357    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2391792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1200000, episode_reward=2869.14 +/- 18.44\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.87e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1200000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -185     |\n",
      "|    critic_loss     | 0.26     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2399792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.87e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1200     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13709    |\n",
      "|    total_timesteps | 1200000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.87e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1204     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13754    |\n",
      "|    total_timesteps | 1204000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -184     |\n",
      "|    critic_loss     | 0.374    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2407792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.88e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1208     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13799    |\n",
      "|    total_timesteps | 1208000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -184     |\n",
      "|    critic_loss     | 0.424    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2415792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.88e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1212     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13844    |\n",
      "|    total_timesteps | 1212000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -185     |\n",
      "|    critic_loss     | 0.28     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2423792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.88e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1216     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13889    |\n",
      "|    total_timesteps | 1216000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -185     |\n",
      "|    critic_loss     | 0.248    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2431792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1220000, episode_reward=2942.43 +/- 51.68\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.94e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1220000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -185     |\n",
      "|    critic_loss     | 0.175    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2439792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.88e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1220     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13935    |\n",
      "|    total_timesteps | 1220000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.88e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1224     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 13981    |\n",
      "|    total_timesteps | 1224000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -185     |\n",
      "|    critic_loss     | 0.505    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2447792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.89e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1228     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14026    |\n",
      "|    total_timesteps | 1228000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -186     |\n",
      "|    critic_loss     | 0.21     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2455792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.89e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1232     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14071    |\n",
      "|    total_timesteps | 1232000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -185     |\n",
      "|    critic_loss     | 0.301    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2463792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.89e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1236     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14116    |\n",
      "|    total_timesteps | 1236000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -186     |\n",
      "|    critic_loss     | 0.225    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2471792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1240000, episode_reward=3004.80 +/- 11.17\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 3e+03    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1240000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -186     |\n",
      "|    critic_loss     | 0.378    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2479792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.9e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 1240     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14161    |\n",
      "|    total_timesteps | 1240000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.9e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 1244     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14207    |\n",
      "|    total_timesteps | 1244000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -186     |\n",
      "|    critic_loss     | 0.36     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2487792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.9e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 1248     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14252    |\n",
      "|    total_timesteps | 1248000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -186     |\n",
      "|    critic_loss     | 0.487    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2495792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.9e+03  |\n",
      "| time/              |          |\n",
      "|    episodes        | 1252     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14297    |\n",
      "|    total_timesteps | 1252000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -186     |\n",
      "|    critic_loss     | 0.218    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2503792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.91e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1256     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14342    |\n",
      "|    total_timesteps | 1256000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -186     |\n",
      "|    critic_loss     | 0.414    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2511792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1260000, episode_reward=2953.80 +/- 13.62\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1260000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -186     |\n",
      "|    critic_loss     | 0.319    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2519792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.91e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1260     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14387    |\n",
      "|    total_timesteps | 1260000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.91e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1264     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14433    |\n",
      "|    total_timesteps | 1264000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -187     |\n",
      "|    critic_loss     | 0.412    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2527792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.91e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1268     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14478    |\n",
      "|    total_timesteps | 1268000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -187     |\n",
      "|    critic_loss     | 0.202    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2535792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.92e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1272     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14523    |\n",
      "|    total_timesteps | 1272000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -187     |\n",
      "|    critic_loss     | 0.288    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2543792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.92e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1276     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14570    |\n",
      "|    total_timesteps | 1276000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -187     |\n",
      "|    critic_loss     | 0.277    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2551792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1280000, episode_reward=2996.53 +/- 15.18\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 3e+03    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1280000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -188     |\n",
      "|    critic_loss     | 0.347    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2559792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.92e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1280     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14618    |\n",
      "|    total_timesteps | 1280000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.93e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1284     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14663    |\n",
      "|    total_timesteps | 1284000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -188     |\n",
      "|    critic_loss     | 0.316    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2567792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.93e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1288     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14708    |\n",
      "|    total_timesteps | 1288000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.47     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2575792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.93e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1292     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14753    |\n",
      "|    total_timesteps | 1292000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.264    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2583792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.94e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1296     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14798    |\n",
      "|    total_timesteps | 1296000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.252    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2591792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1300000, episode_reward=3008.52 +/- 14.78\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 3.01e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1300000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.329    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2599792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.94e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1300     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14844    |\n",
      "|    total_timesteps | 1300000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.94e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1304     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14890    |\n",
      "|    total_timesteps | 1304000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -188     |\n",
      "|    critic_loss     | 0.306    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2607792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.94e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1308     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14935    |\n",
      "|    total_timesteps | 1308000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.199    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2615792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.94e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1312     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 14980    |\n",
      "|    total_timesteps | 1312000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.289    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2623792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1316     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15025    |\n",
      "|    total_timesteps | 1316000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -188     |\n",
      "|    critic_loss     | 0.426    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2631792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1320000, episode_reward=2949.33 +/- 10.26\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1320000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.273    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2639792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1320     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15071    |\n",
      "|    total_timesteps | 1320000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1324     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15117    |\n",
      "|    total_timesteps | 1324000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.263    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2647792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1328     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15162    |\n",
      "|    total_timesteps | 1328000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.216    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2655792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1332     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15207    |\n",
      "|    total_timesteps | 1332000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.408    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2663792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1336     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15252    |\n",
      "|    total_timesteps | 1336000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.439    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2671792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1340000, episode_reward=3020.18 +/- 16.65\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 3.02e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1340000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.358    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2679792  |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1340     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15298    |\n",
      "|    total_timesteps | 1340000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1344     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15343    |\n",
      "|    total_timesteps | 1344000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.207    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2687792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1348     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15389    |\n",
      "|    total_timesteps | 1348000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.279    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2695792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1352     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15434    |\n",
      "|    total_timesteps | 1352000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.601    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2703792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1356     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15479    |\n",
      "|    total_timesteps | 1356000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.309    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2711792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1360000, episode_reward=2888.05 +/- 59.78\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.89e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1360000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.3      |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2719792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1360     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15525    |\n",
      "|    total_timesteps | 1360000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1364     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15570    |\n",
      "|    total_timesteps | 1364000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.374    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2727792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1368     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15615    |\n",
      "|    total_timesteps | 1368000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.238    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2735792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1372     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15660    |\n",
      "|    total_timesteps | 1372000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.267    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2743792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1376     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15705    |\n",
      "|    total_timesteps | 1376000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.19     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2751792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1380000, episode_reward=2985.45 +/- 36.28\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.99e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1380000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.285    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2759792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1380     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15751    |\n",
      "|    total_timesteps | 1380000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1384     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15797    |\n",
      "|    total_timesteps | 1384000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.28     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2767792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1388     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15842    |\n",
      "|    total_timesteps | 1388000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.321    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2775792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1392     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15887    |\n",
      "|    total_timesteps | 1392000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.236    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2783792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1396     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15932    |\n",
      "|    total_timesteps | 1396000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.251    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2791792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1400000, episode_reward=2938.88 +/- 32.36\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.94e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1400000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.436    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2799792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1400     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 15978    |\n",
      "|    total_timesteps | 1400000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1404     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16024    |\n",
      "|    total_timesteps | 1404000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.294    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2807792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1408     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16069    |\n",
      "|    total_timesteps | 1408000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.193    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2815792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1412     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16114    |\n",
      "|    total_timesteps | 1412000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 0.336    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2823792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1416     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16159    |\n",
      "|    total_timesteps | 1416000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.296    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2831792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1420000, episode_reward=2991.34 +/- 9.73\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.99e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1420000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.194    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2839792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1420     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16205    |\n",
      "|    total_timesteps | 1420000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1424     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16250    |\n",
      "|    total_timesteps | 1424000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.321    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2847792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1428     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16295    |\n",
      "|    total_timesteps | 1428000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.339    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2855792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.95e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1432     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16340    |\n",
      "|    total_timesteps | 1432000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -191     |\n",
      "|    critic_loss     | 0.229    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2863792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.96e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1436     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16385    |\n",
      "|    total_timesteps | 1436000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -191     |\n",
      "|    critic_loss     | 0.264    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2871792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1440000, episode_reward=3001.28 +/- 11.81\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 3e+03    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1440000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.397    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2879792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.96e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1440     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16431    |\n",
      "|    total_timesteps | 1440000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.96e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1444     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16477    |\n",
      "|    total_timesteps | 1444000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.45     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2887792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.96e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1448     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16522    |\n",
      "|    total_timesteps | 1448000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.32     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2895792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.97e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1452     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16567    |\n",
      "|    total_timesteps | 1452000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -191     |\n",
      "|    critic_loss     | 0.305    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2903792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.96e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1456     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16612    |\n",
      "|    total_timesteps | 1456000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 0.239    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2911792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1460000, episode_reward=2805.35 +/- 64.42\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.81e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1460000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -191     |\n",
      "|    critic_loss     | 0.403    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2919792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.97e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1460     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16658    |\n",
      "|    total_timesteps | 1460000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.97e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1464     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16703    |\n",
      "|    total_timesteps | 1464000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -191     |\n",
      "|    critic_loss     | 0.272    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2927792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.97e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1468     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16748    |\n",
      "|    total_timesteps | 1468000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -191     |\n",
      "|    critic_loss     | 0.263    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2935792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.97e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1472     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16793    |\n",
      "|    total_timesteps | 1472000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -191     |\n",
      "|    critic_loss     | 0.23     |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2943792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.97e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1476     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16838    |\n",
      "|    total_timesteps | 1476000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -191     |\n",
      "|    critic_loss     | 0.239    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2951792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1480000, episode_reward=3010.92 +/- 17.01\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 3.01e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1480000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -191     |\n",
      "|    critic_loss     | 0.315    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2959792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.98e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1480     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16884    |\n",
      "|    total_timesteps | 1480000  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.98e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1484     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16931    |\n",
      "|    total_timesteps | 1484000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -192     |\n",
      "|    critic_loss     | 0.357    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2967792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.98e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1488     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 16976    |\n",
      "|    total_timesteps | 1488000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -192     |\n",
      "|    critic_loss     | 0.299    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2975792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.98e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1492     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 17022    |\n",
      "|    total_timesteps | 1492000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -192     |\n",
      "|    critic_loss     | 0.266    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2983792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.98e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1496     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 17068    |\n",
      "|    total_timesteps | 1496000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -192     |\n",
      "|    critic_loss     | 0.254    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2991792  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1500000, episode_reward=2962.79 +/- 11.86\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 1e+03    |\n",
      "|    mean_reward     | 2.96e+03 |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1500000  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -192     |\n",
      "|    critic_loss     | 0.275    |\n",
      "|    ent_coef        | 0.001    |\n",
      "|    learning_rate   | 4.35e-05 |\n",
      "|    n_updates       | 2999792  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 2.98e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 1500     |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 17115    |\n",
      "|    total_timesteps | 1500000  |\n",
      "---------------------------------\n",
      "Mean Reward: -1071.18  14.97\n"
     ]
    }
   ],
   "source": [
    "# Numero di ambienti paralleli per il training\n",
    "NUM_ENVS = 4\n",
    "\n",
    "# Wrapper personalizzato per applicare la ricompensa modificata\n",
    "class CustomRewardWrapper(gym.Wrapper):\n",
    "    \"\"\"\n",
    "    Un wrapper personalizzato per modificare la ricompensa dell'ambiente HalfCheetah.\n",
    "    Aggiunge una penalit quando l'agente \"cappotta\" (ovvero quando l'angolo del torso  troppo inclinato).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env):\n",
    "        \"\"\"\n",
    "        Inizializza il wrapper, impostando l'ambiente originale e variabili aggiuntive.\n",
    "\n",
    "        Parametri:\n",
    "        - env: L'ambiente di base (HalfCheetah-v5) che sar avvolto da questo wrapper.\n",
    "        \"\"\"\n",
    "        super().__init__(env)\n",
    "        self.cappottato_start_time = None  # Variabile per monitorare il tempo di \"cappottamento\"\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Esegue un passo nell'ambiente con l'azione data e restituisce le nuove osservazioni,\n",
    "        la ricompensa, e i segnali di terminazione (successo, errore o timeout).\n",
    "\n",
    "        Parametri:\n",
    "        - action: L'azione da eseguire nell'ambiente.\n",
    "\n",
    "        Ritorna:\n",
    "        - obs: Le nuove osservazioni dell'ambiente.\n",
    "        - reward: La ricompensa ottenuta per l'azione eseguita.\n",
    "        - terminated: Un segnale che indica se l'episodio  terminato (successo o errore).\n",
    "        - truncated: Un segnale che indica se l'episodio  stato troncato (timeout o condizioni specifiche).\n",
    "        - info: Dati aggiuntivi sull'episodio (di solito informazioni di debug).\n",
    "        \"\"\"\n",
    "\n",
    "        # Passa l'azione all'ambiente e ottieni le nuove osservazioni e ricompensa\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "\n",
    "        # Ottieni l'angolo del torso (per determinare se il modello  caduto)\n",
    "        torso_angle = self.env.unwrapped.data.qpos[2]\n",
    "\n",
    "        # Se l'angolo del torso  sotto una certa soglia, il modello  \"cappottato\"\n",
    "        if torso_angle < -0.7:\n",
    "            if self.cappottato_start_time is None:\n",
    "                self.cappottato_start_time = time.time()  # Registra il tempo del cappottamento\n",
    "            # Calcola la penalit in base al tempo di cappottamento\n",
    "            tempo_cappottato = time.time() - self.cappottato_start_time\n",
    "            penalty = 50 * tempo_cappottato  # Penalit crescente\n",
    "            reward -= penalty  # Applica la penalit alla ricompensa\n",
    "        else:\n",
    "            self.cappottato_start_time = None  # Resetta il timer quando non  pi cappottato\n",
    "\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "# Funzione per creare l'ambiente HalfCheetah con parametri personalizzati\n",
    "def make_env():\n",
    "    \"\"\"\n",
    "    Crea e restituisce un ambiente HalfCheetah con parametri personalizzati per il training.\n",
    "    \"\"\"\n",
    "    def _init():\n",
    "        # Crea l'ambiente HalfCheetah con parametri specifici\n",
    "        env = gym.make(\"HalfCheetah-v5\",\n",
    "                        reset_noise_scale=0.13635555699602933,\n",
    "                        forward_reward_weight=0.7151140526343989,\n",
    "                        ctrl_cost_weight=0.19342622590821706)\n",
    "        env = Monitor(env)  # Aggiungi il monitor per registrare le metriche\n",
    "        env = CustomRewardWrapper(env)  # Applica il wrapper personalizzato per la ricompensa\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "# Creazione degli ambienti per il training utilizzando SubprocVecEnv per eseguire il training in parallelo\n",
    "env = SubprocVecEnv([make_env() for _ in range(NUM_ENVS)])  # Creazione di NUM_ENVS ambienti paralleli\n",
    "env = VecNormalize(env, norm_obs=True, norm_reward=False, clip_obs=10.)  # Normalizzazione delle osservazioni\n",
    "\n",
    "# Selezione automatica del dispositivo (GPU se disponibile, altrimenti CPU)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Parametri del modello SAC\n",
    "model_params = {\n",
    "    \"policy\": \"MlpPolicy\",  # Politica Multi-layer perceptron\n",
    "    \"env\": env,  # Ambiente di addestramento\n",
    "    \"learning_rate\": 4.3539588088977104e-05,  # Tasso di apprendimento\n",
    "    \"buffer_size\": 500000,  # Dimensione del buffer di esperienza\n",
    "    \"batch_size\": 256,  # Dimensione del batch per l'addestramento\n",
    "    \"tau\": 0.013929154106819306,  # Parametro per il soft update delle reti\n",
    "    \"gamma\": 0.9843911115842067,  # Fattore di sconto\n",
    "    \"train_freq\": 1,  # Frequenza di aggiornamento del modello\n",
    "    \"gradient_steps\": 8,  # Numero di passaggi per l'aggiornamento del gradiente\n",
    "    \"ent_coef\": 0.001,  # Coefficiente di entropia\n",
    "    \"verbose\": 1,  # Output verboso per il monitoraggio del training\n",
    "    \"tensorboard_log\": \"./sac_HalfCheetah_tensorboard/\",  # Percorso per il log di TensorBoard\n",
    "    \"device\": device,  # Dispositivo per il training (CPU o GPU)\n",
    "    \"policy_kwargs\": dict(net_arch=[256, 256, 128])  # Architettura della rete neurale\n",
    "}\n",
    "\n",
    "# Creazione dell'ambiente di valutazione per testare il modello addestrato\n",
    "eval_env = DummyVecEnv([make_env()])  # Usa DummyVecEnv per l'ambiente di valutazione\n",
    "eval_env = VecNormalize(eval_env, norm_obs=True, norm_reward=False, clip_obs=10., training=False)  # Normalizzazione delle osservazioni\n",
    "\n",
    "# Callback per la valutazione del modello e salvataggio dei migliori modelli\n",
    "eval_callback = EvalCallback(eval_env, best_model_save_path=\"./logs/best_model\",\n",
    "                             log_path=\"./logs/\", eval_freq=5000, deterministic=True, render=False)\n",
    "\n",
    "# Callback per il salvataggio dei checkpoint durante l'allenamento\n",
    "checkpoint_callback = CheckpointCallback(save_freq=5000, save_path=\"./logs/checkpoints/\",\n",
    "                                         name_prefix=\"sac_halfcheetah_checkpoint\")\n",
    "\n",
    "# Creazione e training del modello SAC con i parametri definiti\n",
    "model = SAC(**model_params)\n",
    "model.learn(total_timesteps=1_500_000, callback=CallbackList([eval_callback, checkpoint_callback]))\n",
    "\n",
    "# Salvataggio del modello e dei parametri di normalizzazione\n",
    "model.save(\"sac_HalfCheetah_model\")  # Salva il modello addestrato\n",
    "env.save(\"vecnormalize_HalfCheetah.pkl\")  # Salva i parametri di normalizzazione\n",
    "\n",
    "# Caricamento del modello e dei parametri di normalizzazione per la valutazione\n",
    "model = SAC.load(\"sac_HalfCheetah_model\", device=device)  # Carica il modello addestrato\n",
    "eval_env = VecNormalize.load(\"vecnormalize_HalfCheetah.pkl\", eval_env)  # Carica i parametri di normalizzazione\n",
    "eval_env.training = False  # Disabilita la normalizzazione per la valutazione\n",
    "eval_env.reset()  # Reset dell'ambiente di valutazione\n",
    "\n",
    "# Funzione per la valutazione del modello\n",
    "def evaluate_agent(model, env, episodes=100):\n",
    "    \"\"\"\n",
    "    Valuta le performance dell'agente su un certo numero di episodi.\n",
    "\n",
    "    Parametri:\n",
    "    - model: Il modello addestrato da valutare.\n",
    "    - env: L'ambiente di valutazione.\n",
    "    - episodes: Numero di episodi per la valutazione.\n",
    "\n",
    "    Ritorna:\n",
    "    - La ricompensa media e la deviazione standard delle ricompense ottenute.\n",
    "    \"\"\"\n",
    "    mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=episodes, deterministic=True)\n",
    "    print(f\"Mean Reward: {mean_reward:.2f}  {std_reward:.2f}\")\n",
    "    return mean_reward, std_reward\n",
    "\n",
    "# Valutazione del modello addestrato\n",
    "mean_reward_trained, std_reward_trained = evaluate_agent(model, eval_env, episodes=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio del modello addestrato\n",
    "model.save(\"sac_HalfCheetah_model\")\n",
    "# Salviamo il modello addestrato in un file chiamato 'sac_HalfCheetah_model'\n",
    "# Questo file conterr tutti i parametri e le configurazioni del modello SAC che sono stati allenati.\n",
    "\n",
    "# Salvataggio dei parametri di normalizzazione\n",
    "env.save(\"vecnormalize_HalfCheetah.pkl\")\n",
    "# Salviamo i parametri di normalizzazione dell'ambiente in un file chiamato 'vecnormalize_HalfCheetah.pkl'\n",
    "# Questo file contiene le statistiche di normalizzazione delle osservazioni (norm_obs) e delle ricompense (norm_reward)\n",
    "# che sono state applicate durante l'allenamento, cos che possano essere riutilizzati per mantenere la coerenza\n",
    "# durante la fase di valutazione o inferenza.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricando dati da: ./sac_HalfCheetah_tensorboard/SAC_2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "# Percorso principale della cartella di log di TensorBoard\n",
    "log_dir = \"./sac_HalfCheetah_tensorboard/\"\n",
    "\n",
    "# Specifica manualmente quale sottocartella utilizzare per i dati di TensorBoard\n",
    "selected_subdir = \"SAC_2\"  # Cambia il nome della sottocartella in base alla versione\n",
    "\n",
    "# Percorso completo della sottocartella selezionata\n",
    "selected_path = os.path.join(log_dir, selected_subdir)\n",
    "\n",
    "# Verifica che la sottocartella esista\n",
    "if not os.path.exists(selected_path):\n",
    "    raise FileNotFoundError(f\"La cartella {selected_subdir} non esiste in {log_dir}\")\n",
    "\n",
    "# Conferma il percorso di caricamento dei dati\n",
    "print(f\"Caricando dati da: {selected_path}\")\n",
    "\n",
    "# Trova il file degli eventi di TensorBoard all'interno della sottocartella selezionata\n",
    "event_file = None\n",
    "for root, dirs, files in os.walk(selected_path):\n",
    "    for file in files:\n",
    "        if \"events.out.tfevents\" in file:  # Cerca il file degli eventi\n",
    "            event_file = os.path.join(root, file)\n",
    "            break\n",
    "\n",
    "# Verifica che sia stato trovato almeno un file degli eventi\n",
    "if event_file is None:\n",
    "    raise FileNotFoundError(f\"Nessun file TensorBoard trovato in {selected_path}\")\n",
    "\n",
    "# Carica i dati dal file degli eventi di TensorBoard\n",
    "event_acc = EventAccumulator(event_file)\n",
    "event_acc.Reload()\n",
    "\n",
    "# Estrai i dati relativi ai timesteps e alle ricompense medie\n",
    "timesteps = []\n",
    "mean_rewards = []\n",
    "\n",
    "# Estrai le ricompense medie per ogni passo (step) nel training\n",
    "for event in event_acc.Scalars(\"rollout/ep_rew_mean\"):\n",
    "    timesteps.append(event.step)\n",
    "    mean_rewards.append(event.value)\n",
    "\n",
    "# Creazione del grafico per visualizzare il progresso dell'allenamento\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(timesteps, mean_rewards, label=\"Mean Reward\", color=\"blue\")\n",
    "plt.xlabel(\"Timesteps\")  # Etichetta per l'asse x (numero di passi)\n",
    "plt.ylabel(\"Mean Episodic Reward\")  # Etichetta per l'asse y (ricompensa media per episodio)\n",
    "plt.title(f\"Training Progress ({selected_subdir}): Reward vs Timesteps\")  # Titolo del grafico\n",
    "plt.legend()  # Legenda per il grafico\n",
    "plt.grid(True)  # Mostra la griglia\n",
    "plt.show()  # Mostra il grafico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Policy: Mean Reward: 3001.31  83.02\n",
      "Random Policy: Mean Reward: -457.79  52.60\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Percorsi dei file salvati\n",
    "model_path = \"./sac_HalfCheetah_model.zip\"\n",
    "vecnormalize_path = \"./vecnormalize_HalfCheetah.pkl\"\n",
    "\n",
    "# Verifica che i file esistano prima di caricarli\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Modello non trovato: {model_path}\")\n",
    "if not os.path.exists(vecnormalize_path):\n",
    "    raise FileNotFoundError(f\"File di normalizzazione non trovato: {vecnormalize_path}\")\n",
    "\n",
    "# Selezione automatica del dispositivo (CPU o GPU)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Caricamento del modello addestrato\n",
    "model = SAC.load(model_path, device=device)\n",
    "\n",
    "# Wrapper personalizzato per applicare la ricompensa modificata in caso di caduta\n",
    "class CustomRewardWrapper(gym.Wrapper):\n",
    "    \"\"\"\n",
    "    Questo wrapper personalizzato applica una penalit se l'agente cade.\n",
    "    La penalit aumenta nel tempo che l'agente resta in caduta.\n",
    "\n",
    "    Attributi:\n",
    "    - cappottato_start_time: tempo in cui l'agente  caduto per la prima volta.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env):\n",
    "        \"\"\"\n",
    "        Inizializza il wrapper, salvando l'ambiente di base.\n",
    "        \"\"\"\n",
    "        super().__init__(env)\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Esegue un passo nell'ambiente, applicando la penalit se l'agente  caduto.\n",
    "\n",
    "        Parametri:\n",
    "        - action: l'azione scelta dall'agente.\n",
    "\n",
    "        Ritorna:\n",
    "        - obs: le nuove osservazioni.\n",
    "        - reward: la ricompensa modificata.\n",
    "        - terminated: se l'episodio  terminato.\n",
    "        - truncated: se l'episodio  stato troncato.\n",
    "        - info: informazioni aggiuntive sull'ambiente.\n",
    "        \"\"\"\n",
    "        # Passo base nell'ambiente\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "\n",
    "        # Angolo del torso per determinare se l'agente  caduto\n",
    "        torso_angle = self.env.unwrapped.data.qpos[2]\n",
    "\n",
    "        if not hasattr(self, 'cappottato_start_time'):  # Inizializza al primo step\n",
    "            self.cappottato_start_time = None\n",
    "\n",
    "        if torso_angle < -0.7:  # Se  caduto\n",
    "            if self.cappottato_start_time is None:  # Se  la prima volta che cade\n",
    "                self.cappottato_start_time = time.time()  # Registra il tempo\n",
    "\n",
    "            # Calcola la durata della caduta\n",
    "            tempo_cappottato = time.time() - self.cappottato_start_time\n",
    "\n",
    "            # Penalit cumulativa basata sul tempo in caduta\n",
    "            penalty = 50 * tempo_cappottato\n",
    "            reward -= penalty  # Applica la penalit alla ricompensa\n",
    "\n",
    "        else:  # Se non  pi caduto\n",
    "            self.cappottato_start_time = None  # Resetta il timer della caduta\n",
    "\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "# Funzione per creare un ambiente con il wrapper personalizzato\n",
    "def make_env():\n",
    "    \"\"\"\n",
    "    Crea e restituisce un nuovo ambiente HalfCheetah-v5 con la normalizzazione e la ricompensa personalizzata.\n",
    "\n",
    "    Ritorna:\n",
    "    - Una funzione che inizializza l'ambiente.\n",
    "    \"\"\"\n",
    "    def _init():\n",
    "        env = gym.make(\"HalfCheetah-v5\",\n",
    "                        reset_noise_scale=0.13635555699602933,\n",
    "                        forward_reward_weight=0.7151140526343989,\n",
    "                        ctrl_cost_weight=0.19342622590821706)\n",
    "        env = Monitor(env)  # Monitorizza l'ambiente per salvare le informazioni sugli episodi\n",
    "        env = CustomRewardWrapper(env)  # Applica il wrapper personalizzato\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "# Creazione dell'ambiente di valutazione\n",
    "eval_env = DummyVecEnv([make_env()])\n",
    "eval_env = VecNormalize.load(vecnormalize_path, eval_env)  # Carica la normalizzazione\n",
    "eval_env.training = False  # Disabilita la normalizzazione in fase di test\n",
    "eval_env.reset()\n",
    "\n",
    "# Funzione per valutare una policy casuale\n",
    "def evaluate_random_policy(env, episodes=100):\n",
    "    \"\"\"\n",
    "    Valuta una policy casuale su un ambiente vettorizzato.\n",
    "\n",
    "    Parametri:\n",
    "    - env: L'ambiente di simulazione (normalizzato e vettorizzato).\n",
    "    - episodes: Numero di episodi da eseguire per la valutazione.\n",
    "\n",
    "    Ritorna:\n",
    "    - La ricompensa media e la deviazione standard delle ricompense ottenute.\n",
    "    \"\"\"\n",
    "    total_rewards = []\n",
    "    for _ in range(episodes):\n",
    "        obs = env.reset()\n",
    "        done = [False] * env.num_envs\n",
    "        episode_rewards = np.zeros(env.num_envs)\n",
    "        while not all(done):\n",
    "            # Esegui azioni casuali per ciascun ambiente\n",
    "            actions = [env.action_space.sample() for _ in range(env.num_envs)]\n",
    "            obs, rewards, done, _ = env.step(actions)\n",
    "            episode_rewards += rewards\n",
    "        total_rewards.extend(episode_rewards)\n",
    "\n",
    "    # Calcola la ricompensa media e la deviazione standard\n",
    "    mean_reward_random = np.mean(total_rewards)\n",
    "    std_reward_random = np.std(total_rewards)\n",
    "    return mean_reward_random, std_reward_random\n",
    "\n",
    "# Valutazione della policy addestrata\n",
    "mean_reward_trained, std_reward_trained = evaluate_policy(model, eval_env, n_eval_episodes=100, deterministic=True)\n",
    "\n",
    "# Valutazione della policy casuale\n",
    "mean_reward_random, std_reward_random = evaluate_random_policy(eval_env, episodes=100)\n",
    "\n",
    "# Stampa dei risultati\n",
    "print(f\"Trained Policy: Mean Reward: {mean_reward_trained:.2f}  {std_reward_trained:.2f}\")\n",
    "print(f\"Random Policy: Mean Reward: {mean_reward_random:.2f}  {std_reward_random:.2f}\")\n",
    "\n",
    "# Creazione del grafico di confronto tra la policy addestrata e quella casuale\n",
    "labels = ['Random Policy', 'Trained Policy']\n",
    "means = [mean_reward_random, mean_reward_trained]\n",
    "stds = [std_reward_random, std_reward_trained]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(labels, means, yerr=stds, capsize=10, color=['skyblue', 'lightgreen'])\n",
    "plt.ylabel('Mean Episodic Reward')\n",
    "plt.title('Policy Comparison')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
