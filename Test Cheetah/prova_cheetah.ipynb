{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, VecNormalize, DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback, CallbackList\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabiodigregorio/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/gymnasium/envs/registration.py:734: UserWarning: \u001b[33mWARN: The environment is being initialised with render_mode='none' that is not in the possible render_modes (['human', 'rgb_array', 'depth_array']).\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/fabiodigregorio/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/gymnasium/envs/registration.py:734: UserWarning: \u001b[33mWARN: The environment is being initialised with render_mode='none' that is not in the possible render_modes (['human', 'rgb_array', 'depth_array']).\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/fabiodigregorio/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/gymnasium/envs/registration.py:734: UserWarning: \u001b[33mWARN: The environment is being initialised with render_mode='none' that is not in the possible render_modes (['human', 'rgb_array', 'depth_array']).\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/fabiodigregorio/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/gymnasium/envs/registration.py:734: UserWarning: \u001b[33mWARN: The environment is being initialised with render_mode='none' that is not in the possible render_modes (['human', 'rgb_array', 'depth_array']).\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/fabiodigregorio/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/gymnasium/envs/registration.py:734: UserWarning: \u001b[33mWARN: The environment is being initialised with render_mode='none' that is not in the possible render_modes (['human', 'rgb_array', 'depth_array']).\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n",
      "Logging to ./ppo_HalfCheetah_tensorboard/PPO_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabiodigregorio/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -341     |\n",
      "| time/              |          |\n",
      "|    fps             | 1443     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 4096     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -331        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 597         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018291216 |\n",
      "|    clip_fraction        | 0.0615      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -8.53       |\n",
      "|    explained_variance   | -0.342      |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.308      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.444       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -335        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019289358 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -8.57       |\n",
      "|    explained_variance   | 0.0873      |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.279      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -328        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 484         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015750686 |\n",
      "|    clip_fraction        | 0.0675      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -8.61       |\n",
      "|    explained_variance   | -0.0947     |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-1.58 +/- 1.94\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | -1.58       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017147878 |\n",
      "|    clip_fraction        | 0.0729      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -8.63       |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.305      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.157       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -314     |\n",
      "| time/              |          |\n",
      "|    fps             | 404      |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 50       |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -309        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 402         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016368473 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -8.67       |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.326      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -306        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019227797 |\n",
      "|    clip_fraction        | 0.0928      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -8.7        |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.282      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -297        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 406         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023025818 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -8.72       |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.291      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -291        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 406         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017945468 |\n",
      "|    clip_fraction        | 0.0824      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -8.75       |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.228      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=234.76 +/- 7.61\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 235         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016529778 |\n",
      "|    clip_fraction        | 0.0807      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -8.79       |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.316      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.128       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -286     |\n",
      "| time/              |          |\n",
      "|    fps             | 382      |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 106      |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -282        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 384         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017069597 |\n",
      "|    clip_fraction        | 0.0895      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -8.83       |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.279      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -282       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 386        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 127        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01831078 |\n",
      "|    clip_fraction        | 0.0931     |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -8.88      |\n",
      "|    explained_variance   | 0.656      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.297     |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.022     |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 0.128      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -279       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 388        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 137        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02077368 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -8.91      |\n",
      "|    explained_variance   | 0.731      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.28      |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0248    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 0.177      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -279        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 390         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016624412 |\n",
      "|    clip_fraction        | 0.0793      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -8.95       |\n",
      "|    explained_variance   | 0.642       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.312      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-62.83 +/- 16.27\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | -62.8       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 60000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017031368 |\n",
      "|    clip_fraction        | 0.0911      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -8.99       |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.32       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -276     |\n",
      "| time/              |          |\n",
      "|    fps             | 375      |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 163      |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -268        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 376         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 174         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016397685 |\n",
      "|    clip_fraction        | 0.0802      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -9.03       |\n",
      "|    explained_variance   | 0.569       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.309      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -264        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 378         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016646212 |\n",
      "|    clip_fraction        | 0.0756      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -9.07       |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.217      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.305       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -262        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 379         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015802559 |\n",
      "|    clip_fraction        | 0.0759      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -9.1        |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.325      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -262        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 380         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 204         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020087253 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -9.14       |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.301      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.0776      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-88.56 +/- 6.17\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | -88.6       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 80000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016631674 |\n",
      "|    clip_fraction        | 0.0876      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -9.18       |\n",
      "|    explained_variance   | 0.801       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.346      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 0.0916      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -264     |\n",
      "| time/              |          |\n",
      "|    fps             | 370      |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 220      |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -264       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 372        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 231        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01653667 |\n",
      "|    clip_fraction        | 0.0846     |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -9.2       |\n",
      "|    explained_variance   | 0.796      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.333     |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0267    |\n",
      "|    std                  | 1.12       |\n",
      "|    value_loss           | 0.1        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -259       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 373        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 241        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01693548 |\n",
      "|    clip_fraction        | 0.0901     |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -9.21      |\n",
      "|    explained_variance   | 0.676      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.342     |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0236    |\n",
      "|    std                  | 1.13       |\n",
      "|    value_loss           | 0.196      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -255        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 250         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016468912 |\n",
      "|    clip_fraction        | 0.0818      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -9.25       |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.323      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 0.104       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -253        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 376         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015795644 |\n",
      "|    clip_fraction        | 0.0895      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -9.29       |\n",
      "|    explained_variance   | 0.756       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.351      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 0.095       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-146.01 +/- 2.56\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | -146        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018048605 |\n",
      "|    clip_fraction        | 0.0937      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -9.33       |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.353      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 0.0801      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -253     |\n",
      "| time/              |          |\n",
      "|    fps             | 369      |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 277      |\n",
      "|    total_timesteps | 102400   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -246        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 287         |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019332979 |\n",
      "|    clip_fraction        | 0.0961      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -9.38       |\n",
      "|    explained_variance   | 0.763       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.331      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 0.0975      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -239        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 372         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 296         |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015353803 |\n",
      "|    clip_fraction        | 0.0781      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -9.42       |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.323      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 0.127       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -234       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 373        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 306        |\n",
      "|    total_timesteps      | 114688     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01666072 |\n",
      "|    clip_fraction        | 0.0807     |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -9.46      |\n",
      "|    explained_variance   | 0.628      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.356     |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.026     |\n",
      "|    std                  | 1.17       |\n",
      "|    value_loss           | 0.137      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -228        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 374         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018888097 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -9.51       |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.292      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-222.41 +/- 6.69\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | -222        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 120000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018398792 |\n",
      "|    clip_fraction        | 0.0995      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -9.55       |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.302      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -223     |\n",
      "| time/              |          |\n",
      "|    fps             | 368      |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 333      |\n",
      "|    total_timesteps | 122880   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -216        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 343         |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016938271 |\n",
      "|    clip_fraction        | 0.0873      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -9.59       |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.338      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -206        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 352         |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016113337 |\n",
      "|    clip_fraction        | 0.0851      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -9.63       |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.313      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 0.249       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -197        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 372         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 362         |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016163383 |\n",
      "|    clip_fraction        | 0.0898      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -9.67       |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.29       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 0.236       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -189        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 373         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 372         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015924918 |\n",
      "|    clip_fraction        | 0.0836      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -9.71       |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.332      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0278     |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 0.158       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=-6.79 +/- 14.86\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | -6.79       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 140000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017786145 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -9.77       |\n",
      "|    explained_variance   | 0.81        |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.299      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0281     |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -183     |\n",
      "| time/              |          |\n",
      "|    fps             | 368      |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 388      |\n",
      "|    total_timesteps | 143360   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -178       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 369        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 398        |\n",
      "|    total_timesteps      | 147456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01694648 |\n",
      "|    clip_fraction        | 0.087      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -9.82      |\n",
      "|    explained_variance   | 0.671      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.283     |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0295    |\n",
      "|    std                  | 1.25       |\n",
      "|    value_loss           | 0.275      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -173        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 408         |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017455665 |\n",
      "|    clip_fraction        | 0.0955      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -9.85       |\n",
      "|    explained_variance   | 0.799       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.339      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -160        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 372         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 418         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018880729 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -9.88       |\n",
      "|    explained_variance   | 0.843       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.335      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -146        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 373         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 428         |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015992234 |\n",
      "|    clip_fraction        | 0.0834      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -9.92       |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.27       |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 0.278       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=535.10 +/- 49.27\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 535         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 160000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017044414 |\n",
      "|    clip_fraction        | 0.0879      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -9.97       |\n",
      "|    explained_variance   | 0.876       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.329      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 0.237       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -142     |\n",
      "| time/              |          |\n",
      "|    fps             | 368      |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 444      |\n",
      "|    total_timesteps | 163840   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -129        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 454         |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016592912 |\n",
      "|    clip_fraction        | 0.0924      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10         |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.324      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 0.23        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -104        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 463         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021951292 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10         |\n",
      "|    explained_variance   | 0.896       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.248      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0374     |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 0.242       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -85.9      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 371        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 473        |\n",
      "|    total_timesteps      | 176128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01766954 |\n",
      "|    clip_fraction        | 0.0984     |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -10        |\n",
      "|    explained_variance   | 0.85       |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.31      |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.0326    |\n",
      "|    std                  | 1.3        |\n",
      "|    value_loss           | 0.256      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=713.47 +/- 18.55\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 713         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 180000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018486198 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10.1       |\n",
      "|    explained_variance   | 0.88        |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.353      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 0.232       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -66.6    |\n",
      "| time/              |          |\n",
      "|    fps             | 367      |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 489      |\n",
      "|    total_timesteps | 180224   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -51.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 499         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017170904 |\n",
      "|    clip_fraction        | 0.095       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10.1       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.338      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -39.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 509         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018232416 |\n",
      "|    clip_fraction        | 0.0985      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10.1       |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.285      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 0.243       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -25.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 519         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019143473 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10.2       |\n",
      "|    explained_variance   | 0.729       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.322      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0363     |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 0.277       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -7.59      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 371        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 529        |\n",
      "|    total_timesteps      | 196608     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01756978 |\n",
      "|    clip_fraction        | 0.0933     |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -10.2      |\n",
      "|    explained_variance   | 0.392      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.319     |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0333    |\n",
      "|    std                  | 1.33       |\n",
      "|    value_loss           | 0.275      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=966.07 +/- 87.64\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 966         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 200000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018483113 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10.2       |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.321      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 0.288       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 5.76     |\n",
      "| time/              |          |\n",
      "|    fps             | 368      |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 545      |\n",
      "|    total_timesteps | 200704   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 11.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 555         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019681303 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10.3       |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.381      |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 26.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 565         |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017669778 |\n",
      "|    clip_fraction        | 0.0942      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10.3       |\n",
      "|    explained_variance   | 0.896       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.378      |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 35.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 574         |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018363263 |\n",
      "|    clip_fraction        | 0.0909      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10.3       |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.328      |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 0.243       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 51.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 584         |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020593282 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10.4       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.32       |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0374     |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 0.165       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=1067.11 +/- 101.47\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 1.07e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 220000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019128319 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10.4       |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.325      |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 69.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 368      |\n",
      "|    iterations      | 54       |\n",
      "|    time_elapsed    | 600      |\n",
      "|    total_timesteps | 221184   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 84.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 610         |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018461347 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10.5       |\n",
      "|    explained_variance   | 0.843       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.427      |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0349     |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 101        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 369        |\n",
      "|    iterations           | 56         |\n",
      "|    time_elapsed         | 620        |\n",
      "|    total_timesteps      | 229376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01720566 |\n",
      "|    clip_fraction        | 0.0977     |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -10.5      |\n",
      "|    explained_variance   | 0.713      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.358     |\n",
      "|    n_updates            | 550        |\n",
      "|    policy_gradient_loss | -0.0371    |\n",
      "|    std                  | 1.4        |\n",
      "|    value_loss           | 0.215      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 107         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 630         |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020845387 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10.5       |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.327      |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0407     |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 122         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 640         |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017657528 |\n",
      "|    clip_fraction        | 0.095       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10.6       |\n",
      "|    explained_variance   | 0.881       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.375      |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=1358.58 +/- 60.45\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 1.36e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 240000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019931046 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10.6       |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.408      |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0407     |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 138      |\n",
      "| time/              |          |\n",
      "|    fps             | 368      |\n",
      "|    iterations      | 59       |\n",
      "|    time_elapsed    | 656      |\n",
      "|    total_timesteps | 241664   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 145         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 666         |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020117275 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10.6       |\n",
      "|    explained_variance   | 0.794       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.371      |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 0.266       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 158         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 676         |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022371888 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10.7       |\n",
      "|    explained_variance   | 0.904       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.344      |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 0.295       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 161         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 686         |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017342389 |\n",
      "|    clip_fraction        | 0.0868      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10.7       |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.347      |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0342     |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 170         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 695         |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019406341 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10.7       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.421      |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0391     |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 0.127       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=1351.08 +/- 45.53\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 1.35e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 260000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017230816 |\n",
      "|    clip_fraction        | 0.0899      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10.8       |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.391      |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 0.135       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 192      |\n",
      "| time/              |          |\n",
      "|    fps             | 368      |\n",
      "|    iterations      | 64       |\n",
      "|    time_elapsed    | 711      |\n",
      "|    total_timesteps | 262144   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 190        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 368        |\n",
      "|    iterations           | 65         |\n",
      "|    time_elapsed         | 721        |\n",
      "|    total_timesteps      | 266240     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01886277 |\n",
      "|    clip_fraction        | 0.0999     |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -10.8      |\n",
      "|    explained_variance   | 0.846      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.412     |\n",
      "|    n_updates            | 640        |\n",
      "|    policy_gradient_loss | -0.0378    |\n",
      "|    std                  | 1.48       |\n",
      "|    value_loss           | 0.179      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 203         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 731         |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020193469 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10.8       |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.421      |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 0.151       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 216         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 741         |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020280866 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10.9       |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.422      |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0386     |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 228         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 751         |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018056178 |\n",
      "|    clip_fraction        | 0.0923      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10.9       |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.39       |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.037      |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=1521.82 +/- 86.18\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 1.52e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 280000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018799502 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10.9       |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.405      |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0374     |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 0.144       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 238      |\n",
      "| time/              |          |\n",
      "|    fps             | 368      |\n",
      "|    iterations      | 69       |\n",
      "|    time_elapsed    | 767      |\n",
      "|    total_timesteps | 282624   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 252         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 777         |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019040234 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -10.9       |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.402      |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0384     |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 267         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 787         |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018273983 |\n",
      "|    clip_fraction        | 0.0988      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -11         |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.415      |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 0.162       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 278         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 797         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018329421 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -11         |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.435      |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.038      |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 286        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 370        |\n",
      "|    iterations           | 73         |\n",
      "|    time_elapsed         | 806        |\n",
      "|    total_timesteps      | 299008     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02071081 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -11        |\n",
      "|    explained_variance   | 0.928      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.406     |\n",
      "|    n_updates            | 720        |\n",
      "|    policy_gradient_loss | -0.0423    |\n",
      "|    std                  | 1.54       |\n",
      "|    value_loss           | 0.172      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=1260.04 +/- 542.61\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 1.26e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 300000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017964588 |\n",
      "|    clip_fraction        | 0.0969      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.353      |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0384     |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 303      |\n",
      "| time/              |          |\n",
      "|    fps             | 368      |\n",
      "|    iterations      | 74       |\n",
      "|    time_elapsed    | 822      |\n",
      "|    total_timesteps | 303104   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 327        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 368        |\n",
      "|    iterations           | 75         |\n",
      "|    time_elapsed         | 832        |\n",
      "|    total_timesteps      | 307200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01724762 |\n",
      "|    clip_fraction        | 0.0902     |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -11.1      |\n",
      "|    explained_variance   | 0.934      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.442     |\n",
      "|    n_updates            | 740        |\n",
      "|    policy_gradient_loss | -0.0379    |\n",
      "|    std                  | 1.54       |\n",
      "|    value_loss           | 0.126      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 341         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 842         |\n",
      "|    total_timesteps      | 311296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018917412 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.452      |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0404     |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 0.152       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 362        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 369        |\n",
      "|    iterations           | 77         |\n",
      "|    time_elapsed         | 852        |\n",
      "|    total_timesteps      | 315392     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01879654 |\n",
      "|    clip_fraction        | 0.0974     |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -11.1      |\n",
      "|    explained_variance   | 0.459      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.398     |\n",
      "|    n_updates            | 760        |\n",
      "|    policy_gradient_loss | -0.0397    |\n",
      "|    std                  | 1.55       |\n",
      "|    value_loss           | 0.204      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 372         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 862         |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019453727 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.445      |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 0.153       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=1374.92 +/- 428.68\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 1.37e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 320000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019721277 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | 0.896       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.304      |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 385      |\n",
      "| time/              |          |\n",
      "|    fps             | 368      |\n",
      "|    iterations      | 79       |\n",
      "|    time_elapsed    | 878      |\n",
      "|    total_timesteps | 323584   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 404         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 888         |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021277368 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.405      |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 412         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 898         |\n",
      "|    total_timesteps      | 331776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019647604 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.413      |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0415     |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 433         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 908         |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020587578 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | 0.854       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.46       |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 0.128       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 445         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 917         |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020779297 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.481      |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0448     |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 0.096       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=1659.39 +/- 77.44\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 1.66e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 340000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021186292 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -11.3       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.438      |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0436     |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 0.0871      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 491      |\n",
      "| time/              |          |\n",
      "|    fps             | 368      |\n",
      "|    iterations      | 84       |\n",
      "|    time_elapsed    | 933      |\n",
      "|    total_timesteps | 344064   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 512         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 943         |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022481207 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -11.3       |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.427      |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0424     |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 0.0989      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 530         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 953         |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019169845 |\n",
      "|    clip_fraction        | 0.0942      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -11.3       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.475      |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 551         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 963         |\n",
      "|    total_timesteps      | 356352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021080483 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -11.3       |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.473      |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0425     |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 0.0752      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=1669.92 +/- 97.55\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 1.67e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 360000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021508299 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -11.4       |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.454      |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 551      |\n",
      "| time/              |          |\n",
      "|    fps             | 367      |\n",
      "|    iterations      | 88       |\n",
      "|    time_elapsed    | 979      |\n",
      "|    total_timesteps | 360448   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 573        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 368        |\n",
      "|    iterations           | 89         |\n",
      "|    time_elapsed         | 989        |\n",
      "|    total_timesteps      | 364544     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02181258 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -11.4      |\n",
      "|    explained_variance   | 0.966      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.446     |\n",
      "|    n_updates            | 880        |\n",
      "|    policy_gradient_loss | -0.0452    |\n",
      "|    std                  | 1.64       |\n",
      "|    value_loss           | 0.088      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 584         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 999         |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021391481 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -11.5       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.465      |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.043      |\n",
      "|    std                  | 1.65        |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 594         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 1009        |\n",
      "|    total_timesteps      | 372736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020379338 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -11.5       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.439      |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 605         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 1018        |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019727442 |\n",
      "|    clip_fraction        | 0.0977      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -11.5       |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.467      |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0445     |\n",
      "|    std                  | 1.67        |\n",
      "|    value_loss           | 0.0984      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=1754.17 +/- 21.50\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 1.75e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 380000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022034585 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -11.6       |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.449      |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0473     |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 0.11        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 611      |\n",
      "| time/              |          |\n",
      "|    fps             | 368      |\n",
      "|    iterations      | 93       |\n",
      "|    time_elapsed    | 1035     |\n",
      "|    total_timesteps | 380928   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 627        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 368        |\n",
      "|    iterations           | 94         |\n",
      "|    time_elapsed         | 1044       |\n",
      "|    total_timesteps      | 385024     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01869061 |\n",
      "|    clip_fraction        | 0.1        |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -11.6      |\n",
      "|    explained_variance   | 0.913      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.352     |\n",
      "|    n_updates            | 930        |\n",
      "|    policy_gradient_loss | -0.0366    |\n",
      "|    std                  | 1.69       |\n",
      "|    value_loss           | 0.293      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 640         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 1054        |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021741848 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -11.6       |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.433      |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0435     |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 639         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 1064        |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022232559 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -11.7       |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.372      |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0405     |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 626         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 1074        |\n",
      "|    total_timesteps      | 397312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022790855 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -11.7       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.443      |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 0.233       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=1864.01 +/- 43.05\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | 1.86e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 400000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02029373 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -11.8      |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.471     |\n",
      "|    n_updates            | 970        |\n",
      "|    policy_gradient_loss | -0.0411    |\n",
      "|    std                  | 1.74       |\n",
      "|    value_loss           | 0.0862     |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 638      |\n",
      "| time/              |          |\n",
      "|    fps             | 368      |\n",
      "|    iterations      | 98       |\n",
      "|    time_elapsed    | 1090     |\n",
      "|    total_timesteps | 401408   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 636         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 1100        |\n",
      "|    total_timesteps      | 405504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021072363 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -11.8       |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.458      |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0413     |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 640         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 1110        |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022577442 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -11.9       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.426      |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    std                  | 1.77        |\n",
      "|    value_loss           | 0.133       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 645        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 369        |\n",
      "|    iterations           | 101        |\n",
      "|    time_elapsed         | 1120       |\n",
      "|    total_timesteps      | 413696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02033452 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -11.9      |\n",
      "|    explained_variance   | 0.96       |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.441     |\n",
      "|    n_updates            | 1000       |\n",
      "|    policy_gradient_loss | -0.0411    |\n",
      "|    std                  | 1.79       |\n",
      "|    value_loss           | 0.235      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 657         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 1130        |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021119509 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12         |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.496      |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.044      |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=420000, episode_reward=1790.43 +/- 106.81\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 1.79e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 420000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024020232 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12         |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.504      |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.0483     |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 0.059       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 669      |\n",
      "| time/              |          |\n",
      "|    fps             | 368      |\n",
      "|    iterations      | 103      |\n",
      "|    time_elapsed    | 1146     |\n",
      "|    total_timesteps | 421888   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 673         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 1156        |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023767747 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12         |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.487      |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | -0.0489     |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 0.0882      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 688        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 368        |\n",
      "|    iterations           | 105        |\n",
      "|    time_elapsed         | 1166       |\n",
      "|    total_timesteps      | 430080     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02307966 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -12        |\n",
      "|    explained_variance   | 0.438      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.515     |\n",
      "|    n_updates            | 1040       |\n",
      "|    policy_gradient_loss | -0.048     |\n",
      "|    std                  | 1.82       |\n",
      "|    value_loss           | 0.069      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 695         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 1176        |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021877296 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12         |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.495      |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.0464     |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 0.089       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 690         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 1186        |\n",
      "|    total_timesteps      | 438272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021352515 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12.1       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.432      |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.0439     |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 0.148       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=1880.31 +/- 105.74\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 1.88e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 440000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022549883 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12.1       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.483      |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | -0.0455     |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 0.087       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 695      |\n",
      "| time/              |          |\n",
      "|    fps             | 367      |\n",
      "|    iterations      | 108      |\n",
      "|    time_elapsed    | 1202     |\n",
      "|    total_timesteps | 442368   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 702         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 1212        |\n",
      "|    total_timesteps      | 446464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022679608 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12.2       |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.494      |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.0468     |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 0.0976      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1e+03     |\n",
      "|    ep_rew_mean          | 694       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 368       |\n",
      "|    iterations           | 110       |\n",
      "|    time_elapsed         | 1221      |\n",
      "|    total_timesteps      | 450560    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0213398 |\n",
      "|    clip_fraction        | 0.11      |\n",
      "|    clip_range           | 0.274     |\n",
      "|    entropy_loss         | -12.2     |\n",
      "|    explained_variance   | 0.951     |\n",
      "|    learning_rate        | 7.64e-05  |\n",
      "|    loss                 | -0.419    |\n",
      "|    n_updates            | 1090      |\n",
      "|    policy_gradient_loss | -0.0413   |\n",
      "|    std                  | 1.89      |\n",
      "|    value_loss           | 0.202     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 709         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 1231        |\n",
      "|    total_timesteps      | 454656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022493696 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12.2       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.49       |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.0483     |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 0.0905      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 706         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 1241        |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022017807 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12.3       |\n",
      "|    explained_variance   | 0.92        |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.398      |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=460000, episode_reward=1922.72 +/- 82.62\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 1.92e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 460000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023845665 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12.3       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.543      |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.0461     |\n",
      "|    std                  | 1.92        |\n",
      "|    value_loss           | 0.0717      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 724      |\n",
      "| time/              |          |\n",
      "|    fps             | 368      |\n",
      "|    iterations      | 113      |\n",
      "|    time_elapsed    | 1257     |\n",
      "|    total_timesteps | 462848   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 731         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 1267        |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018473934 |\n",
      "|    clip_fraction        | 0.0964      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12.3       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.477      |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    std                  | 1.92        |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 742         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 1277        |\n",
      "|    total_timesteps      | 471040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021775853 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12.3       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.489      |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.0468     |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 0.0728      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 753         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 1287        |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021774739 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.501      |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.045      |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 758         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 1297        |\n",
      "|    total_timesteps      | 479232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021014664 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.42       |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=2090.06 +/- 83.40\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 2.09e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 480000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021562904 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.486      |\n",
      "|    n_updates            | 1170        |\n",
      "|    policy_gradient_loss | -0.0431     |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 764      |\n",
      "| time/              |          |\n",
      "|    fps             | 368      |\n",
      "|    iterations      | 118      |\n",
      "|    time_elapsed    | 1313     |\n",
      "|    total_timesteps | 483328   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 768         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 1323        |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023306996 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12.4       |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.444      |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.0456     |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 0.149       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 758         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 1332        |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020197261 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.451      |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 776         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 1342        |\n",
      "|    total_timesteps      | 495616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021976002 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12.5       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.499      |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.0427     |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 0.141       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 814        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 369        |\n",
      "|    iterations           | 122        |\n",
      "|    time_elapsed         | 1352       |\n",
      "|    total_timesteps      | 499712     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02170546 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -12.6      |\n",
      "|    explained_variance   | 0.95       |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.498     |\n",
      "|    n_updates            | 1210       |\n",
      "|    policy_gradient_loss | -0.0416    |\n",
      "|    std                  | 2.01       |\n",
      "|    value_loss           | 0.117      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=2094.45 +/- 101.78\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 2.09e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 500000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023657756 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12.6       |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.528      |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.0475     |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 0.0595      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 823      |\n",
      "| time/              |          |\n",
      "|    fps             | 368      |\n",
      "|    iterations      | 123      |\n",
      "|    time_elapsed    | 1368     |\n",
      "|    total_timesteps | 503808   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 833         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 1378        |\n",
      "|    total_timesteps      | 507904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021897532 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12.7       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.483      |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    std                  | 2.04        |\n",
      "|    value_loss           | 0.143       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 873         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 1388        |\n",
      "|    total_timesteps      | 512000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021586858 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12.7       |\n",
      "|    explained_variance   | 0.862       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.555      |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.0479     |\n",
      "|    std                  | 2.04        |\n",
      "|    value_loss           | 0.0679      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 877         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 1398        |\n",
      "|    total_timesteps      | 516096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022150269 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12.7       |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.555      |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | -0.0479     |\n",
      "|    std                  | 2.04        |\n",
      "|    value_loss           | 0.0556      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=520000, episode_reward=2230.22 +/- 93.88\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 2.23e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 520000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021744609 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12.7       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.533      |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    std                  | 2.06        |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 876      |\n",
      "| time/              |          |\n",
      "|    fps             | 367      |\n",
      "|    iterations      | 127      |\n",
      "|    time_elapsed    | 1414     |\n",
      "|    total_timesteps | 520192   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 880         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 1424        |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022716148 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.558      |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.0418     |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 0.144       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 892         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 1434        |\n",
      "|    total_timesteps      | 528384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019282732 |\n",
      "|    clip_fraction        | 0.0963      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.539      |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.0411     |\n",
      "|    std                  | 2.1         |\n",
      "|    value_loss           | 0.104       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 891         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 1444        |\n",
      "|    total_timesteps      | 532480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022446997 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.535      |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.0474     |\n",
      "|    std                  | 2.11        |\n",
      "|    value_loss           | 0.0782      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 908         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 369         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 1454        |\n",
      "|    total_timesteps      | 536576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024870763 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.541      |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.0474     |\n",
      "|    std                  | 2.12        |\n",
      "|    value_loss           | 0.0839      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=540000, episode_reward=2131.07 +/- 86.52\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 2.13e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 540000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023467463 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.496      |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -0.0438     |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 0.155       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 918      |\n",
      "| time/              |          |\n",
      "|    fps             | 367      |\n",
      "|    iterations      | 132      |\n",
      "|    time_elapsed    | 1470     |\n",
      "|    total_timesteps | 540672   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 916         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 1480        |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020318482 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0.845       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.47       |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.0408     |\n",
      "|    std                  | 2.16        |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 940         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 1490        |\n",
      "|    total_timesteps      | 548864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019438574 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.527      |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    std                  | 2.18        |\n",
      "|    value_loss           | 0.24        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 924         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 1500        |\n",
      "|    total_timesteps      | 552960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022279782 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -13.1       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.498      |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.0411     |\n",
      "|    std                  | 2.19        |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 934         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 1510        |\n",
      "|    total_timesteps      | 557056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020167261 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -13.1       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.425      |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | -0.0394     |\n",
      "|    std                  | 2.21        |\n",
      "|    value_loss           | 0.23        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=1987.08 +/- 329.29\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 1.99e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 560000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023095947 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -13.1       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.473      |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.0456     |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 948      |\n",
      "| time/              |          |\n",
      "|    fps             | 367      |\n",
      "|    iterations      | 137      |\n",
      "|    time_elapsed    | 1526     |\n",
      "|    total_timesteps | 561152   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 949        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 368        |\n",
      "|    iterations           | 138        |\n",
      "|    time_elapsed         | 1535       |\n",
      "|    total_timesteps      | 565248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02224033 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -13.2      |\n",
      "|    explained_variance   | 0.875      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.51      |\n",
      "|    n_updates            | 1370       |\n",
      "|    policy_gradient_loss | -0.0414    |\n",
      "|    std                  | 2.24       |\n",
      "|    value_loss           | 0.11       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 927         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 1545        |\n",
      "|    total_timesteps      | 569344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021589812 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -13.2       |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.456      |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.0415     |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 0.304       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 925         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 1555        |\n",
      "|    total_timesteps      | 573440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023856355 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -13.3       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.599      |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -0.0451     |\n",
      "|    std                  | 2.27        |\n",
      "|    value_loss           | 0.0492      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 937         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 1565        |\n",
      "|    total_timesteps      | 577536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020462904 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -13.3       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.527      |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.0423     |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 0.139       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=580000, episode_reward=1757.34 +/- 430.39\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 1.76e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 580000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022108976 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -13.3       |\n",
      "|    explained_variance   | 0.87        |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.527      |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.0428     |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 0.165       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 949      |\n",
      "| time/              |          |\n",
      "|    fps             | 367      |\n",
      "|    iterations      | 142      |\n",
      "|    time_elapsed    | 1581     |\n",
      "|    total_timesteps | 581632   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 953         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 1591        |\n",
      "|    total_timesteps      | 585728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022499263 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -13.3       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.553      |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.0447     |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 967         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 1601        |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023144063 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -13.4       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.451      |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    std                  | 2.33        |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 972        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 368        |\n",
      "|    iterations           | 145        |\n",
      "|    time_elapsed         | 1611       |\n",
      "|    total_timesteps      | 593920     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02143929 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -13.4      |\n",
      "|    explained_variance   | 0.983      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.507     |\n",
      "|    n_updates            | 1440       |\n",
      "|    policy_gradient_loss | -0.0409    |\n",
      "|    std                  | 2.35       |\n",
      "|    value_loss           | 0.105      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 969         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 1620        |\n",
      "|    total_timesteps      | 598016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021982044 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -13.5       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.57       |\n",
      "|    n_updates            | 1450        |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    std                  | 2.37        |\n",
      "|    value_loss           | 0.0979      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=2106.62 +/- 102.69\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | 2.11e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 600000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02512248 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -13.5      |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.563     |\n",
      "|    n_updates            | 1460       |\n",
      "|    policy_gradient_loss | -0.0513    |\n",
      "|    std                  | 2.38       |\n",
      "|    value_loss           | 0.029      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 978      |\n",
      "| time/              |          |\n",
      "|    fps             | 367      |\n",
      "|    iterations      | 147      |\n",
      "|    time_elapsed    | 1637     |\n",
      "|    total_timesteps | 602112   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 985         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 1646        |\n",
      "|    total_timesteps      | 606208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021531379 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -13.6       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.448      |\n",
      "|    n_updates            | 1470        |\n",
      "|    policy_gradient_loss | -0.0379     |\n",
      "|    std                  | 2.41        |\n",
      "|    value_loss           | 0.149       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 989         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 1656        |\n",
      "|    total_timesteps      | 610304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022269323 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -13.6       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.566      |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.0489     |\n",
      "|    std                  | 2.42        |\n",
      "|    value_loss           | 0.0673      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 986         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 1666        |\n",
      "|    total_timesteps      | 614400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022306226 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -13.7       |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.422      |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.0415     |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 0.244       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 982         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 1676        |\n",
      "|    total_timesteps      | 618496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021715228 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -13.7       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.566      |\n",
      "|    n_updates            | 1500        |\n",
      "|    policy_gradient_loss | -0.0439     |\n",
      "|    std                  | 2.46        |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=620000, episode_reward=2051.33 +/- 94.74\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 2.05e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 620000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021844983 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -13.8       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.521      |\n",
      "|    n_updates            | 1510        |\n",
      "|    policy_gradient_loss | -0.0452     |\n",
      "|    std                  | 2.48        |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 995      |\n",
      "| time/              |          |\n",
      "|    fps             | 367      |\n",
      "|    iterations      | 152      |\n",
      "|    time_elapsed    | 1692     |\n",
      "|    total_timesteps | 622592   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.01e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 1702        |\n",
      "|    total_timesteps      | 626688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025588043 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -13.8       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.565      |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | -0.0515     |\n",
      "|    std                  | 2.48        |\n",
      "|    value_loss           | 0.0436      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 996         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 1712        |\n",
      "|    total_timesteps      | 630784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019545138 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -13.8       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.545      |\n",
      "|    n_updates            | 1530        |\n",
      "|    policy_gradient_loss | -0.0371     |\n",
      "|    std                  | 2.51        |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 994         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 155         |\n",
      "|    time_elapsed         | 1722        |\n",
      "|    total_timesteps      | 634880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018926905 |\n",
      "|    clip_fraction        | 0.0886      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -13.9       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.591      |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 0.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 985         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 1732        |\n",
      "|    total_timesteps      | 638976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021525152 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -13.9       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.419      |\n",
      "|    n_updates            | 1550        |\n",
      "|    policy_gradient_loss | -0.0405     |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 0.237       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=2073.04 +/- 110.56\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 2.07e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 640000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022741131 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -14         |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.548      |\n",
      "|    n_updates            | 1560        |\n",
      "|    policy_gradient_loss | -0.0436     |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 0.0969      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 979      |\n",
      "| time/              |          |\n",
      "|    fps             | 367      |\n",
      "|    iterations      | 157      |\n",
      "|    time_elapsed    | 1748     |\n",
      "|    total_timesteps | 643072   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 993        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 368        |\n",
      "|    iterations           | 158        |\n",
      "|    time_elapsed         | 1758       |\n",
      "|    total_timesteps      | 647168     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02243872 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -14        |\n",
      "|    explained_variance   | 0.942      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.545     |\n",
      "|    n_updates            | 1570       |\n",
      "|    policy_gradient_loss | -0.0487    |\n",
      "|    std                  | 2.59       |\n",
      "|    value_loss           | 0.0782     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1e+03      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 368        |\n",
      "|    iterations           | 159        |\n",
      "|    time_elapsed         | 1768       |\n",
      "|    total_timesteps      | 651264     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02312285 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -14        |\n",
      "|    explained_variance   | 0.479      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.569     |\n",
      "|    n_updates            | 1580       |\n",
      "|    policy_gradient_loss | -0.0468    |\n",
      "|    std                  | 2.59       |\n",
      "|    value_loss           | 0.0543     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.03e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 1778        |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024028944 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -14.1       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.601      |\n",
      "|    n_updates            | 1590        |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    std                  | 2.6         |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.03e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 161         |\n",
      "|    time_elapsed         | 1788        |\n",
      "|    total_timesteps      | 659456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022398423 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -14.1       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.569      |\n",
      "|    n_updates            | 1600        |\n",
      "|    policy_gradient_loss | -0.0431     |\n",
      "|    std                  | 2.62        |\n",
      "|    value_loss           | 0.145       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=660000, episode_reward=2280.80 +/- 98.42\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 2.28e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 660000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023739096 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -14.1       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.627      |\n",
      "|    n_updates            | 1610        |\n",
      "|    policy_gradient_loss | -0.0509     |\n",
      "|    std                  | 2.63        |\n",
      "|    value_loss           | 0.0439      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.03e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 367      |\n",
      "|    iterations      | 162      |\n",
      "|    time_elapsed    | 1804     |\n",
      "|    total_timesteps | 663552   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.05e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 368        |\n",
      "|    iterations           | 163        |\n",
      "|    time_elapsed         | 1814       |\n",
      "|    total_timesteps      | 667648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02206368 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -14.1      |\n",
      "|    explained_variance   | 0.454      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.597     |\n",
      "|    n_updates            | 1620       |\n",
      "|    policy_gradient_loss | -0.0501    |\n",
      "|    std                  | 2.64       |\n",
      "|    value_loss           | 0.0371     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.09e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 368        |\n",
      "|    iterations           | 164        |\n",
      "|    time_elapsed         | 1823       |\n",
      "|    total_timesteps      | 671744     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01887256 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -14.2      |\n",
      "|    explained_variance   | 0.957      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.538     |\n",
      "|    n_updates            | 1630       |\n",
      "|    policy_gradient_loss | -0.0395    |\n",
      "|    std                  | 2.65       |\n",
      "|    value_loss           | 0.165      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.11e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 1833        |\n",
      "|    total_timesteps      | 675840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024206173 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -14.2       |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.555      |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | -0.0464     |\n",
      "|    std                  | 2.67        |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.12e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 1843        |\n",
      "|    total_timesteps      | 679936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023374688 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -14.2       |\n",
      "|    explained_variance   | 0.906       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.598      |\n",
      "|    n_updates            | 1650        |\n",
      "|    policy_gradient_loss | -0.0531     |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 0.053       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=680000, episode_reward=2372.93 +/- 128.02\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 2.37e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 680000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020574693 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -14.3       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.515      |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    std                  | 2.71        |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.12e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 367      |\n",
      "|    iterations      | 167      |\n",
      "|    time_elapsed    | 1860     |\n",
      "|    total_timesteps | 684032   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.14e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 1870        |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021610435 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -14.3       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.514      |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | -0.0422     |\n",
      "|    std                  | 2.73        |\n",
      "|    value_loss           | 0.0991      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.15e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 1880        |\n",
      "|    total_timesteps      | 692224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023499597 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -14.3       |\n",
      "|    explained_variance   | -0.00929    |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.616      |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | -0.043      |\n",
      "|    std                  | 2.74        |\n",
      "|    value_loss           | 0.0587      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.17e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 368        |\n",
      "|    iterations           | 170        |\n",
      "|    time_elapsed         | 1890       |\n",
      "|    total_timesteps      | 696320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02228317 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -14.4      |\n",
      "|    explained_variance   | 0.971      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.602     |\n",
      "|    n_updates            | 1690       |\n",
      "|    policy_gradient_loss | -0.0411    |\n",
      "|    std                  | 2.76       |\n",
      "|    value_loss           | 0.0765     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=2427.69 +/- 92.57\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 2.43e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 700000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022558628 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -14.4       |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.541      |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    std                  | 2.77        |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.16e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 367      |\n",
      "|    iterations      | 171      |\n",
      "|    time_elapsed    | 1906     |\n",
      "|    total_timesteps | 700416   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.16e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 1916        |\n",
      "|    total_timesteps      | 704512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021525685 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -14.4       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.448      |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    std                  | 2.79        |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.18e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 1926        |\n",
      "|    total_timesteps      | 708608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023475362 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -14.5       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.585      |\n",
      "|    n_updates            | 1720        |\n",
      "|    policy_gradient_loss | -0.0486     |\n",
      "|    std                  | 2.81        |\n",
      "|    value_loss           | 0.0406      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.19e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 368        |\n",
      "|    iterations           | 174        |\n",
      "|    time_elapsed         | 1936       |\n",
      "|    total_timesteps      | 712704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02127387 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -14.5      |\n",
      "|    explained_variance   | 0.947      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.597     |\n",
      "|    n_updates            | 1730       |\n",
      "|    policy_gradient_loss | -0.0408    |\n",
      "|    std                  | 2.82       |\n",
      "|    value_loss           | 0.112      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.2e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 1946        |\n",
      "|    total_timesteps      | 716800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021063277 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -14.5       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.604      |\n",
      "|    n_updates            | 1740        |\n",
      "|    policy_gradient_loss | -0.0415     |\n",
      "|    std                  | 2.84        |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=720000, episode_reward=2256.72 +/- 137.91\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 2.26e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 720000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020225886 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -14.6       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.571      |\n",
      "|    n_updates            | 1750        |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 0.127       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.2e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 367      |\n",
      "|    iterations      | 176      |\n",
      "|    time_elapsed    | 1962     |\n",
      "|    total_timesteps | 720896   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.21e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 1972        |\n",
      "|    total_timesteps      | 724992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020394359 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -14.6       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.599      |\n",
      "|    n_updates            | 1760        |\n",
      "|    policy_gradient_loss | -0.0431     |\n",
      "|    std                  | 2.88        |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.24e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 1982        |\n",
      "|    total_timesteps      | 729088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023776164 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -14.6       |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.595      |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | -0.0504     |\n",
      "|    std                  | 2.89        |\n",
      "|    value_loss           | 0.0579      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.23e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 368        |\n",
      "|    iterations           | 179        |\n",
      "|    time_elapsed         | 1992       |\n",
      "|    total_timesteps      | 733184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02301148 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -14.7      |\n",
      "|    explained_variance   | 0.901      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.43      |\n",
      "|    n_updates            | 1780       |\n",
      "|    policy_gradient_loss | -0.0414    |\n",
      "|    std                  | 2.92       |\n",
      "|    value_loss           | 0.156      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.27e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 2002        |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022050783 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -14.7       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.593      |\n",
      "|    n_updates            | 1790        |\n",
      "|    policy_gradient_loss | -0.0421     |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 0.143       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=740000, episode_reward=2373.99 +/- 71.95\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 2.37e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 740000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022927465 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -14.8       |\n",
      "|    explained_variance   | 0.772       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.566      |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.0413     |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 0.127       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.27e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 367      |\n",
      "|    iterations      | 181      |\n",
      "|    time_elapsed    | 2018     |\n",
      "|    total_timesteps | 741376   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.27e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 367        |\n",
      "|    iterations           | 182        |\n",
      "|    time_elapsed         | 2028       |\n",
      "|    total_timesteps      | 745472     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02181501 |\n",
      "|    clip_fraction        | 0.104      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -14.8      |\n",
      "|    explained_variance   | 0.984      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.616     |\n",
      "|    n_updates            | 1810       |\n",
      "|    policy_gradient_loss | -0.0403    |\n",
      "|    std                  | 3          |\n",
      "|    value_loss           | 0.0883     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.24e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 367        |\n",
      "|    iterations           | 183        |\n",
      "|    time_elapsed         | 2038       |\n",
      "|    total_timesteps      | 749568     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02087393 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -14.9      |\n",
      "|    explained_variance   | 0.964      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.542     |\n",
      "|    n_updates            | 1820       |\n",
      "|    policy_gradient_loss | -0.0381    |\n",
      "|    std                  | 3.03       |\n",
      "|    value_loss           | 0.227      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.24e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 2048        |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020291314 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -15         |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.524      |\n",
      "|    n_updates            | 1830        |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    std                  | 3.08        |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.26e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 2057        |\n",
      "|    total_timesteps      | 757760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024244089 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -15         |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.613      |\n",
      "|    n_updates            | 1840        |\n",
      "|    policy_gradient_loss | -0.0426     |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 0.0573      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=760000, episode_reward=2464.75 +/- 35.85\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 2.46e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 760000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021395426 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -15         |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.652      |\n",
      "|    n_updates            | 1850        |\n",
      "|    policy_gradient_loss | -0.0475     |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 0.0397      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.26e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 367      |\n",
      "|    iterations      | 186      |\n",
      "|    time_elapsed    | 2074     |\n",
      "|    total_timesteps | 761856   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.27e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 2084        |\n",
      "|    total_timesteps      | 765952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022767484 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -15         |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.607      |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | -0.0507     |\n",
      "|    std                  | 3.1         |\n",
      "|    value_loss           | 0.0498      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.29e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 367        |\n",
      "|    iterations           | 188        |\n",
      "|    time_elapsed         | 2093       |\n",
      "|    total_timesteps      | 770048     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02519289 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -15        |\n",
      "|    explained_variance   | 0.518      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.648     |\n",
      "|    n_updates            | 1870       |\n",
      "|    policy_gradient_loss | -0.0527    |\n",
      "|    std                  | 3.11       |\n",
      "|    value_loss           | 0.0477     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.3e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 2103        |\n",
      "|    total_timesteps      | 774144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024201948 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -15.1       |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.644      |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.0495     |\n",
      "|    std                  | 3.13        |\n",
      "|    value_loss           | 0.0517      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.3e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 2113        |\n",
      "|    total_timesteps      | 778240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022788394 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -15.1       |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.607      |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | -0.048      |\n",
      "|    std                  | 3.14        |\n",
      "|    value_loss           | 0.0478      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=780000, episode_reward=2418.88 +/- 128.13\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 2.42e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 780000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018813863 |\n",
      "|    clip_fraction        | 0.0988      |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -15.1       |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.572      |\n",
      "|    n_updates            | 1900        |\n",
      "|    policy_gradient_loss | -0.04       |\n",
      "|    std                  | 3.16        |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.32e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 367      |\n",
      "|    iterations      | 191      |\n",
      "|    time_elapsed    | 2129     |\n",
      "|    total_timesteps | 782336   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.32e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 367        |\n",
      "|    iterations           | 192        |\n",
      "|    time_elapsed         | 2139       |\n",
      "|    total_timesteps      | 786432     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02161356 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -15.2      |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.648     |\n",
      "|    n_updates            | 1910       |\n",
      "|    policy_gradient_loss | -0.04      |\n",
      "|    std                  | 3.18       |\n",
      "|    value_loss           | 0.134      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.32e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 2149        |\n",
      "|    total_timesteps      | 790528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022820871 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -15.2       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.667      |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | -0.0513     |\n",
      "|    std                  | 3.19        |\n",
      "|    value_loss           | 0.0352      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.34e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 194         |\n",
      "|    time_elapsed         | 2159        |\n",
      "|    total_timesteps      | 794624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021834197 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -15.2       |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.636      |\n",
      "|    n_updates            | 1930        |\n",
      "|    policy_gradient_loss | -0.0488     |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 0.0425      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.35e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 195         |\n",
      "|    time_elapsed         | 2169        |\n",
      "|    total_timesteps      | 798720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024663147 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -15.2       |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.617      |\n",
      "|    n_updates            | 1940        |\n",
      "|    policy_gradient_loss | -0.0515     |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 0.0434      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=2511.34 +/- 33.71\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 2.51e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 800000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020758372 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -15.3       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.479      |\n",
      "|    n_updates            | 1950        |\n",
      "|    policy_gradient_loss | -0.0386     |\n",
      "|    std                  | 3.25        |\n",
      "|    value_loss           | 0.154       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.35e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 367      |\n",
      "|    iterations      | 196      |\n",
      "|    time_elapsed    | 2185     |\n",
      "|    total_timesteps | 802816   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1e+03     |\n",
      "|    ep_rew_mean          | 1.37e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 367       |\n",
      "|    iterations           | 197       |\n",
      "|    time_elapsed         | 2195      |\n",
      "|    total_timesteps      | 806912    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0228303 |\n",
      "|    clip_fraction        | 0.121     |\n",
      "|    clip_range           | 0.274     |\n",
      "|    entropy_loss         | -15.3     |\n",
      "|    explained_variance   | 0.957     |\n",
      "|    learning_rate        | 7.64e-05  |\n",
      "|    loss                 | -0.581    |\n",
      "|    n_updates            | 1960      |\n",
      "|    policy_gradient_loss | -0.0419   |\n",
      "|    std                  | 3.28      |\n",
      "|    value_loss           | 0.18      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.34e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 198         |\n",
      "|    time_elapsed         | 2205        |\n",
      "|    total_timesteps      | 811008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020398742 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -15.4       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.606      |\n",
      "|    n_updates            | 1970        |\n",
      "|    policy_gradient_loss | -0.04       |\n",
      "|    std                  | 3.31        |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.35e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 199         |\n",
      "|    time_elapsed         | 2215        |\n",
      "|    total_timesteps      | 815104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022055004 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -15.4       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.64       |\n",
      "|    n_updates            | 1980        |\n",
      "|    policy_gradient_loss | -0.045      |\n",
      "|    std                  | 3.34        |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.37e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 2224        |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023438806 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -15.5       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.628      |\n",
      "|    n_updates            | 1990        |\n",
      "|    policy_gradient_loss | -0.048      |\n",
      "|    std                  | 3.35        |\n",
      "|    value_loss           | 0.033       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=820000, episode_reward=2497.08 +/- 113.61\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 2.5e+03     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 820000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023746572 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -15.5       |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.661      |\n",
      "|    n_updates            | 2000        |\n",
      "|    policy_gradient_loss | -0.0504     |\n",
      "|    std                  | 3.37        |\n",
      "|    value_loss           | 0.0312      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.39e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 367      |\n",
      "|    iterations      | 201      |\n",
      "|    time_elapsed    | 2241     |\n",
      "|    total_timesteps | 823296   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.38e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 367        |\n",
      "|    iterations           | 202        |\n",
      "|    time_elapsed         | 2251       |\n",
      "|    total_timesteps      | 827392     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02285538 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -15.5      |\n",
      "|    explained_variance   | 0.953      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.622     |\n",
      "|    n_updates            | 2010       |\n",
      "|    policy_gradient_loss | -0.0459    |\n",
      "|    std                  | 3.39       |\n",
      "|    value_loss           | 0.11       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.38e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 203         |\n",
      "|    time_elapsed         | 2261        |\n",
      "|    total_timesteps      | 831488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020925455 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -15.5       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.66       |\n",
      "|    n_updates            | 2020        |\n",
      "|    policy_gradient_loss | -0.0471     |\n",
      "|    std                  | 3.4         |\n",
      "|    value_loss           | 0.0419      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.41e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 204         |\n",
      "|    time_elapsed         | 2271        |\n",
      "|    total_timesteps      | 835584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023304168 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -15.5       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.617      |\n",
      "|    n_updates            | 2030        |\n",
      "|    policy_gradient_loss | -0.0429     |\n",
      "|    std                  | 3.41        |\n",
      "|    value_loss           | 0.0904      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 368         |\n",
      "|    iterations           | 205         |\n",
      "|    time_elapsed         | 2280        |\n",
      "|    total_timesteps      | 839680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022043234 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -15.6       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.585      |\n",
      "|    n_updates            | 2040        |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    std                  | 3.44        |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=840000, episode_reward=2432.71 +/- 126.99\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 2.43e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 840000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021676932 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -15.6       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.532      |\n",
      "|    n_updates            | 2050        |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    std                  | 3.45        |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.41e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 367      |\n",
      "|    iterations      | 206      |\n",
      "|    time_elapsed    | 2296     |\n",
      "|    total_timesteps | 843776   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 207         |\n",
      "|    time_elapsed         | 2307        |\n",
      "|    total_timesteps      | 847872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022203788 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -15.7       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.39       |\n",
      "|    n_updates            | 2060        |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    std                  | 3.48        |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.45e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 208         |\n",
      "|    time_elapsed         | 2317        |\n",
      "|    total_timesteps      | 851968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023036966 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -15.7       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.632      |\n",
      "|    n_updates            | 2070        |\n",
      "|    policy_gradient_loss | -0.0456     |\n",
      "|    std                  | 3.5         |\n",
      "|    value_loss           | 0.123       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 209         |\n",
      "|    time_elapsed         | 2327        |\n",
      "|    total_timesteps      | 856064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020253312 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -15.8       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.616      |\n",
      "|    n_updates            | 2080        |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    std                  | 3.55        |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=860000, episode_reward=2559.17 +/- 124.99\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | 2.56e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 860000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02072902 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -15.8      |\n",
      "|    explained_variance   | 0.973      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.542     |\n",
      "|    n_updates            | 2090       |\n",
      "|    policy_gradient_loss | -0.0387    |\n",
      "|    std                  | 3.58       |\n",
      "|    value_loss           | 0.198      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.38e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 367      |\n",
      "|    iterations      | 210      |\n",
      "|    time_elapsed    | 2343     |\n",
      "|    total_timesteps | 860160   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.37e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 211         |\n",
      "|    time_elapsed         | 2353        |\n",
      "|    total_timesteps      | 864256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020489864 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -15.9       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.597      |\n",
      "|    n_updates            | 2100        |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    std                  | 3.62        |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.35e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 2363        |\n",
      "|    total_timesteps      | 868352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024155071 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -15.9       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.676      |\n",
      "|    n_updates            | 2110        |\n",
      "|    policy_gradient_loss | -0.045      |\n",
      "|    std                  | 3.66        |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.33e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 213         |\n",
      "|    time_elapsed         | 2372        |\n",
      "|    total_timesteps      | 872448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022881068 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -16         |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.555      |\n",
      "|    n_updates            | 2120        |\n",
      "|    policy_gradient_loss | -0.0422     |\n",
      "|    std                  | 3.69        |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.33e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 214         |\n",
      "|    time_elapsed         | 2382        |\n",
      "|    total_timesteps      | 876544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022540737 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -16.1       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.649      |\n",
      "|    n_updates            | 2130        |\n",
      "|    policy_gradient_loss | -0.0422     |\n",
      "|    std                  | 3.73        |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=880000, episode_reward=2560.92 +/- 55.07\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 2.56e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 880000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023590518 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -16.1       |\n",
      "|    explained_variance   | 0.751       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.674      |\n",
      "|    n_updates            | 2140        |\n",
      "|    policy_gradient_loss | -0.047      |\n",
      "|    std                  | 3.76        |\n",
      "|    value_loss           | 0.0651      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.33e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 367      |\n",
      "|    iterations      | 215      |\n",
      "|    time_elapsed    | 2399     |\n",
      "|    total_timesteps | 880640   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.34e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 367        |\n",
      "|    iterations           | 216        |\n",
      "|    time_elapsed         | 2409       |\n",
      "|    total_timesteps      | 884736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02493095 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -16.1      |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.695     |\n",
      "|    n_updates            | 2150       |\n",
      "|    policy_gradient_loss | -0.0507    |\n",
      "|    std                  | 3.77       |\n",
      "|    value_loss           | 0.0297     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.33e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 367        |\n",
      "|    iterations           | 217        |\n",
      "|    time_elapsed         | 2419       |\n",
      "|    total_timesteps      | 888832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02355599 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -16.2      |\n",
      "|    explained_variance   | 0.155      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.616     |\n",
      "|    n_updates            | 2160       |\n",
      "|    policy_gradient_loss | -0.0462    |\n",
      "|    std                  | 3.81       |\n",
      "|    value_loss           | 0.0585     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1e+03     |\n",
      "|    ep_rew_mean          | 1.33e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 367       |\n",
      "|    iterations           | 218       |\n",
      "|    time_elapsed         | 2428      |\n",
      "|    total_timesteps      | 892928    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0224358 |\n",
      "|    clip_fraction        | 0.123     |\n",
      "|    clip_range           | 0.274     |\n",
      "|    entropy_loss         | -16.2     |\n",
      "|    explained_variance   | 0.942     |\n",
      "|    learning_rate        | 7.64e-05  |\n",
      "|    loss                 | -0.647    |\n",
      "|    n_updates            | 2170      |\n",
      "|    policy_gradient_loss | -0.0469   |\n",
      "|    std                  | 3.83      |\n",
      "|    value_loss           | 0.104     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.33e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 219         |\n",
      "|    time_elapsed         | 2438        |\n",
      "|    total_timesteps      | 897024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023342406 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -16.3       |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.658      |\n",
      "|    n_updates            | 2180        |\n",
      "|    policy_gradient_loss | -0.0493     |\n",
      "|    std                  | 3.86        |\n",
      "|    value_loss           | 0.0511      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=2748.25 +/- 134.81\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 2.75e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 900000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024496261 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -16.3       |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.683      |\n",
      "|    n_updates            | 2190        |\n",
      "|    policy_gradient_loss | -0.0543     |\n",
      "|    std                  | 3.87        |\n",
      "|    value_loss           | 0.0394      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.34e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 367      |\n",
      "|    iterations      | 220      |\n",
      "|    time_elapsed    | 2455     |\n",
      "|    total_timesteps | 901120   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.34e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 2464        |\n",
      "|    total_timesteps      | 905216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022490632 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -16.3       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.601      |\n",
      "|    n_updates            | 2200        |\n",
      "|    policy_gradient_loss | -0.0415     |\n",
      "|    std                  | 3.91        |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.37e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 222         |\n",
      "|    time_elapsed         | 2474        |\n",
      "|    total_timesteps      | 909312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020866232 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -16.4       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.655      |\n",
      "|    n_updates            | 2210        |\n",
      "|    policy_gradient_loss | -0.0418     |\n",
      "|    std                  | 3.94        |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.35e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 223         |\n",
      "|    time_elapsed         | 2484        |\n",
      "|    total_timesteps      | 913408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019270461 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -16.4       |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.521      |\n",
      "|    n_updates            | 2220        |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    std                  | 3.97        |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.34e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 367        |\n",
      "|    iterations           | 224        |\n",
      "|    time_elapsed         | 2494       |\n",
      "|    total_timesteps      | 917504     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02273547 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -16.4      |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.686     |\n",
      "|    n_updates            | 2230       |\n",
      "|    policy_gradient_loss | -0.0447    |\n",
      "|    std                  | 3.99       |\n",
      "|    value_loss           | 0.111      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=920000, episode_reward=2275.58 +/- 985.56\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 2.28e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 920000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021276817 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -16.5       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.698      |\n",
      "|    n_updates            | 2240        |\n",
      "|    policy_gradient_loss | -0.045      |\n",
      "|    std                  | 4.02        |\n",
      "|    value_loss           | 0.0992      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.33e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 367      |\n",
      "|    iterations      | 225      |\n",
      "|    time_elapsed    | 2510     |\n",
      "|    total_timesteps | 921600   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.34e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 226         |\n",
      "|    time_elapsed         | 2520        |\n",
      "|    total_timesteps      | 925696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023263108 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -16.5       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.655      |\n",
      "|    n_updates            | 2250        |\n",
      "|    policy_gradient_loss | -0.0427     |\n",
      "|    std                  | 4.05        |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.34e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 227         |\n",
      "|    time_elapsed         | 2530        |\n",
      "|    total_timesteps      | 929792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021222144 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -16.5       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.67       |\n",
      "|    n_updates            | 2260        |\n",
      "|    policy_gradient_loss | -0.0446     |\n",
      "|    std                  | 4.07        |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.3e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 228         |\n",
      "|    time_elapsed         | 2540        |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020381736 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -16.6       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.645      |\n",
      "|    n_updates            | 2270        |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    std                  | 4.1         |\n",
      "|    value_loss           | 0.167       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.27e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 367        |\n",
      "|    iterations           | 229        |\n",
      "|    time_elapsed         | 2550       |\n",
      "|    total_timesteps      | 937984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02108743 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -16.7      |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.674     |\n",
      "|    n_updates            | 2280       |\n",
      "|    policy_gradient_loss | -0.039     |\n",
      "|    std                  | 4.15       |\n",
      "|    value_loss           | 0.134      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=940000, episode_reward=2682.62 +/- 67.62\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | 2.68e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 940000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02439291 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -16.7      |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.693     |\n",
      "|    n_updates            | 2290       |\n",
      "|    policy_gradient_loss | -0.0443    |\n",
      "|    std                  | 4.19       |\n",
      "|    value_loss           | 0.115      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.28e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 366      |\n",
      "|    iterations      | 230      |\n",
      "|    time_elapsed    | 2567     |\n",
      "|    total_timesteps | 942080   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.29e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 367        |\n",
      "|    iterations           | 231        |\n",
      "|    time_elapsed         | 2577       |\n",
      "|    total_timesteps      | 946176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02288077 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -16.8      |\n",
      "|    explained_variance   | 0.864      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.691     |\n",
      "|    n_updates            | 2300       |\n",
      "|    policy_gradient_loss | -0.0462    |\n",
      "|    std                  | 4.22       |\n",
      "|    value_loss           | 0.11       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.3e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 232         |\n",
      "|    time_elapsed         | 2587        |\n",
      "|    total_timesteps      | 950272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021281738 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -16.8       |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.613      |\n",
      "|    n_updates            | 2310        |\n",
      "|    policy_gradient_loss | -0.043      |\n",
      "|    std                  | 4.24        |\n",
      "|    value_loss           | 0.0931      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.32e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 233         |\n",
      "|    time_elapsed         | 2597        |\n",
      "|    total_timesteps      | 954368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022757059 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -16.8       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.679      |\n",
      "|    n_updates            | 2320        |\n",
      "|    policy_gradient_loss | -0.0424     |\n",
      "|    std                  | 4.28        |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.32e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 2607        |\n",
      "|    total_timesteps      | 958464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021587744 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -16.9       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.595      |\n",
      "|    n_updates            | 2330        |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    std                  | 4.31        |\n",
      "|    value_loss           | 0.127       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=960000, episode_reward=2605.51 +/- 129.90\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 2.61e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 960000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021254687 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -16.9       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.706      |\n",
      "|    n_updates            | 2340        |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    std                  | 4.34        |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.34e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 366      |\n",
      "|    iterations      | 235      |\n",
      "|    time_elapsed    | 2623     |\n",
      "|    total_timesteps | 962560   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.36e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 2633        |\n",
      "|    total_timesteps      | 966656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022518877 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -17         |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.67       |\n",
      "|    n_updates            | 2350        |\n",
      "|    policy_gradient_loss | -0.0416     |\n",
      "|    std                  | 4.38        |\n",
      "|    value_loss           | 0.0774      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.34e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 237         |\n",
      "|    time_elapsed         | 2643        |\n",
      "|    total_timesteps      | 970752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023203794 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -17         |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.659      |\n",
      "|    n_updates            | 2360        |\n",
      "|    policy_gradient_loss | -0.0431     |\n",
      "|    std                  | 4.43        |\n",
      "|    value_loss           | 0.128       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.34e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 367        |\n",
      "|    iterations           | 238        |\n",
      "|    time_elapsed         | 2653       |\n",
      "|    total_timesteps      | 974848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02107564 |\n",
      "|    clip_fraction        | 0.0978     |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -17.1      |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.702     |\n",
      "|    n_updates            | 2370       |\n",
      "|    policy_gradient_loss | -0.0419    |\n",
      "|    std                  | 4.46       |\n",
      "|    value_loss           | 0.155      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.33e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 239         |\n",
      "|    time_elapsed         | 2662        |\n",
      "|    total_timesteps      | 978944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023243112 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -17.1       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.704      |\n",
      "|    n_updates            | 2380        |\n",
      "|    policy_gradient_loss | -0.0431     |\n",
      "|    std                  | 4.49        |\n",
      "|    value_loss           | 0.0923      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=980000, episode_reward=2422.06 +/- 448.43\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | 2.42e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 980000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02328321 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -17.1      |\n",
      "|    explained_variance   | 0.974      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.712     |\n",
      "|    n_updates            | 2390       |\n",
      "|    policy_gradient_loss | -0.0474    |\n",
      "|    std                  | 4.51       |\n",
      "|    value_loss           | 0.0314     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.35e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 366      |\n",
      "|    iterations      | 240      |\n",
      "|    time_elapsed    | 2679     |\n",
      "|    total_timesteps | 983040   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.35e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 366         |\n",
      "|    iterations           | 241         |\n",
      "|    time_elapsed         | 2689        |\n",
      "|    total_timesteps      | 987136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022605628 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -17.2       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.667      |\n",
      "|    n_updates            | 2400        |\n",
      "|    policy_gradient_loss | -0.0421     |\n",
      "|    std                  | 4.56        |\n",
      "|    value_loss           | 0.0752      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1e+03    |\n",
      "|    ep_rew_mean          | 1.35e+03 |\n",
      "| time/                   |          |\n",
      "|    fps                  | 367      |\n",
      "|    iterations           | 242      |\n",
      "|    time_elapsed         | 2699     |\n",
      "|    total_timesteps      | 991232   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.021029 |\n",
      "|    clip_fraction        | 0.11     |\n",
      "|    clip_range           | 0.274    |\n",
      "|    entropy_loss         | -17.2    |\n",
      "|    explained_variance   | 0.978    |\n",
      "|    learning_rate        | 7.64e-05 |\n",
      "|    loss                 | -0.711   |\n",
      "|    n_updates            | 2410     |\n",
      "|    policy_gradient_loss | -0.0423  |\n",
      "|    std                  | 4.59     |\n",
      "|    value_loss           | 0.083    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 1.34e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 367        |\n",
      "|    iterations           | 243        |\n",
      "|    time_elapsed         | 2709       |\n",
      "|    total_timesteps      | 995328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02057401 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.274      |\n",
      "|    entropy_loss         | -17.3      |\n",
      "|    explained_variance   | 0.958      |\n",
      "|    learning_rate        | 7.64e-05   |\n",
      "|    loss                 | -0.504     |\n",
      "|    n_updates            | 2420       |\n",
      "|    policy_gradient_loss | -0.0423    |\n",
      "|    std                  | 4.64       |\n",
      "|    value_loss           | 0.144      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 1.32e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 367         |\n",
      "|    iterations           | 244         |\n",
      "|    time_elapsed         | 2719        |\n",
      "|    total_timesteps      | 999424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022156347 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -17.3       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.693      |\n",
      "|    n_updates            | 2430        |\n",
      "|    policy_gradient_loss | -0.0436     |\n",
      "|    std                  | 4.67        |\n",
      "|    value_loss           | 0.12        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=2364.41 +/- 649.65\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 2.36e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1000000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021066934 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.274       |\n",
      "|    entropy_loss         | -17.4       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 7.64e-05    |\n",
      "|    loss                 | -0.639      |\n",
      "|    n_updates            | 2440        |\n",
      "|    policy_gradient_loss | -0.04       |\n",
      "|    std                  | 4.73        |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 1.31e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 366      |\n",
      "|    iterations      | 245      |\n",
      "|    time_elapsed    | 2735     |\n",
      "|    total_timesteps | 1003520  |\n",
      "---------------------------------\n",
      "Mean Reward: 226.69  83.90\n"
     ]
    }
   ],
   "source": [
    "# Numero di ambienti paralleli per il training\n",
    "NUM_ENVS = 4\n",
    "\n",
    "# Funzione per creare un ambiente monitorato\n",
    "def make_env():\n",
    "    return lambda: Monitor(gym.make(\"HalfCheetah-v5\",\n",
    "                                    reset_noise_scale=0.16861882648143064,\n",
    "                                    forward_reward_weight=0.9408203240971191,\n",
    "                                    ctrl_cost_weight=0.09598052645324526,\n",
    "                                    render_mode='none'))\n",
    "\n",
    "# Creazione degli ambienti per il training\n",
    "env = SubprocVecEnv([make_env() for _ in range(NUM_ENVS)])\n",
    "env = VecNormalize(env, norm_obs=True, norm_reward=True, clip_obs=10.)\n",
    "\n",
    "# Selezione automatica del device (GPU/CPU)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# Modifica della funzione di ricompensa per penalizzare la postura errata\n",
    "def custom_reward(env):\n",
    "    state = env.unwrapped.sim.data.qpos\n",
    "    torso_angle = state[2]  # Assumendo che il terzo stato sia l'angolo del torso\n",
    "    forward_velocity = state[3]  # Velocit in avanti\n",
    "    penalty = -abs(torso_angle) * 0.5  # Penalizzazione per torso inclinato\n",
    "    reward = forward_velocity * 0.8 + penalty\n",
    "    return reward\n",
    "\n",
    "# Parametri del modello\n",
    "model_params = {\n",
    "    \"policy\": \"MlpPolicy\",\n",
    "    \"env\": env,\n",
    "    \"learning_rate\": 7.642236216979812e-05,\n",
    "    \"n_steps\": 1024,\n",
    "    \"batch_size\": 64,\n",
    "    \"n_epochs\": 10,\n",
    "    \"gamma\": 0.9955582618297791,\n",
    "    \"gae_lambda\": 0.9653759042371923,\n",
    "    \"clip_range\": 0.2742621016643404,\n",
    "    \"ent_coef\": 0.038083013834726225,\n",
    "    \"verbose\": 1,\n",
    "    \"tensorboard_log\": \"./ppo_HalfCheetah_tensorboard/\",\n",
    "    \"device\": device,\n",
    "    \"policy_kwargs\": dict(net_arch=[256, 256, 128])\n",
    "}\n",
    "\n",
    "# Creazione dell'ambiente di valutazione\n",
    "eval_env = DummyVecEnv([make_env()])  # DummyVecEnv per evitare problemi con SubprocVecEnv\n",
    "eval_env = VecNormalize(eval_env, norm_obs=True, norm_reward=True, clip_obs=10., training=False)\n",
    "\n",
    "# Callback per valutazione e salvataggi\n",
    "eval_callback = EvalCallback(eval_env, best_model_save_path=\"./logs/best_model\",\n",
    "                             log_path=\"./logs/\", eval_freq=5000, deterministic=True, render=False)\n",
    "checkpoint_callback = CheckpointCallback(save_freq=10000, save_path=\"./logs/checkpoints/\",\n",
    "                                         name_prefix=\"ppo_halfcheetah_checkpoint\")\n",
    "\n",
    "# Creazione e training del modello\n",
    "model = PPO(**model_params)\n",
    "model.learn(total_timesteps=1_000_000, callback=CallbackList([eval_callback, checkpoint_callback]))\n",
    "\n",
    "# Salvataggio del modello e normalizzazione\n",
    "model.save(\"ppo_HalfCheetah_model\")\n",
    "env.save(\"vecnormalize_HalfCheetah.pkl\")\n",
    "\n",
    "# Caricamento del modello e della normalizzazione per la valutazione\n",
    "model = PPO.load(\"ppo_HalfCheetah_model\", device=device)\n",
    "eval_env = VecNormalize.load(\"vecnormalize_HalfCheetah.pkl\", eval_env)\n",
    "eval_env.training = False\n",
    "\n",
    "def evaluate_agent(model, env, episodes=100):\n",
    "    mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=episodes, deterministic=True)\n",
    "    print(f\"Mean Reward: {mean_reward:.2f}  {std_reward:.2f}\")\n",
    "    return mean_reward, std_reward\n",
    "\n",
    "# Valutazione del modello allenato\n",
    "mean_reward_trained, std_reward_trained = evaluate_agent(model, eval_env, episodes=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Salviamo il modello\n",
    "model.save(\"ppo_HalfCheetah_model\")\n",
    "env.save(\"vecnormalize_HalfCheetah.pkl\")    # salviamo anche i parametri di normalizzazione\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video salvato in videos/halfcheetah_best_policy.mp4\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, VecNormalize, DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback, CallbackList\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "NUM_ENVS=2\n",
    "def make_envv():\n",
    "    return Monitor(gym.make(\"HalfCheetah-v5\",\n",
    "                            reset_noise_scale=0.16861882648143064,\n",
    "                            forward_reward_weight=0.9408203240971191,\n",
    "                            ctrl_cost_weight=0.09598052645324526,\n",
    "                            render_mode='rgb_array'))\n",
    "\n",
    "# Creiamo gli ambienti paralleli\n",
    "env = SubprocVecEnv([make_envv for _ in range(NUM_ENVS)])\n",
    "env = VecNormalize(env, norm_obs=True, norm_reward=True, clip_obs=10.)\n",
    "# Funzione per visualizzare la policy in tempo reale e registrare il video\n",
    "def render_and_record_policy(model_path, output_filename=\"videos/halfcheetah_best_policy.mp4\", episodes=1):\n",
    "    os.makedirs(\"\", exist_ok=True)\n",
    "    env = make_envv()\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "    env = VecNormalize.load(\"vecnormalize_HalfCheetah.pkl\", env)\n",
    "    env.training = False  # Disabilita la normalizzazione della reward per la valutazione\n",
    "    env.norm_reward = False\n",
    "    \n",
    "    model = PPO.load(model_path, env=env)\n",
    "    obs = env.reset()\n",
    "    frames = []\n",
    "    \n",
    "    for _ in range(episodes * 1000):  # Esegui abbastanza step per registrare un episodio completo\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, _, done, _ = env.step(action)\n",
    "        frames.append(env.render(mode='rgb_array'))\n",
    "        if done:\n",
    "            obs = env.reset()\n",
    "    \n",
    "    imageio.mimsave(output_filename, frames, fps=30)\n",
    "    print(f\"Video salvato in {output_filename}\")\n",
    "    env.close()\n",
    "\n",
    "# Registra un video della policy ottimale\n",
    "render_and_record_policy(\"ppo_HalfCheetah_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
