{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 11:20:01.328 Python[61323:3308937] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-02-23 11:20:01.328 Python[61323:3308937] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 31\u001B[0m\n\u001B[1;32m     29\u001B[0m action, _ \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(obs)\n\u001B[1;32m     30\u001B[0m obs, rewards, dones, infos \u001B[38;5;241m=\u001B[39m render_env\u001B[38;5;241m.\u001B[39mstep(action)  \u001B[38;5;66;03m# Corretto: 4 valori\u001B[39;00m\n\u001B[0;32m---> 31\u001B[0m \u001B[43mrender_env\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Mostra l'ambiente a schermo (se render_mode='human')\u001B[39;00m\n\u001B[1;32m     32\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.01\u001B[39m)\n\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m# Gestione del 'done' (dones può essere un array anche con 1 solo env)\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:390\u001B[0m, in \u001B[0;36mVecEnvWrapper.render\u001B[0;34m(self, mode)\u001B[0m\n\u001B[1;32m    389\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mrender\u001B[39m(\u001B[38;5;28mself\u001B[39m, mode: Optional[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[np\u001B[38;5;241m.\u001B[39mndarray]:\n\u001B[0;32m--> 390\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvenv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:104\u001B[0m, in \u001B[0;36mDummyVecEnv.render\u001B[0;34m(self, mode)\u001B[0m\n\u001B[1;32m     97\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mrender\u001B[39m(\u001B[38;5;28mself\u001B[39m, mode: Optional[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[np\u001B[38;5;241m.\u001B[39mndarray]:\n\u001B[1;32m     98\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     99\u001B[0m \u001B[38;5;124;03m    Gym environment rendering. If there are multiple environments then\u001B[39;00m\n\u001B[1;32m    100\u001B[0m \u001B[38;5;124;03m    they are tiled together in one image via ``BaseVecEnv.render()``.\u001B[39;00m\n\u001B[1;32m    101\u001B[0m \n\u001B[1;32m    102\u001B[0m \u001B[38;5;124;03m    :param mode: The rendering type.\u001B[39;00m\n\u001B[1;32m    103\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 104\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:251\u001B[0m, in \u001B[0;36mVecEnv.render\u001B[0;34m(self, mode)\u001B[0m\n\u001B[1;32m    247\u001B[0m \u001B[38;5;66;03m# mode == self.render_mode == \"human\"\u001B[39;00m\n\u001B[1;32m    248\u001B[0m \u001B[38;5;66;03m# In that case, we try to call `self.env.render()` but it might\u001B[39;00m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;66;03m# crash for subprocesses\u001B[39;00m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrender_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhuman\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 251\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv_method\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrender\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    252\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    254\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrgb_array\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhuman\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    255\u001B[0m     \u001B[38;5;66;03m# call the render method of the environments\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:130\u001B[0m, in \u001B[0;36mDummyVecEnv.env_method\u001B[0;34m(self, method_name, indices, *method_args, **method_kwargs)\u001B[0m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Call instance methods of vectorized environments.\"\"\"\u001B[39;00m\n\u001B[1;32m    129\u001B[0m target_envs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_target_envs(indices)\n\u001B[0;32m--> 130\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [env_i\u001B[38;5;241m.\u001B[39mget_wrapper_attr(method_name)(\u001B[38;5;241m*\u001B[39mmethod_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmethod_kwargs) \u001B[38;5;28;01mfor\u001B[39;00m env_i \u001B[38;5;129;01min\u001B[39;00m target_envs]\n",
      "File \u001B[0;32m~/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:130\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Call instance methods of vectorized environments.\"\"\"\u001B[39;00m\n\u001B[1;32m    129\u001B[0m target_envs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_target_envs(indices)\n\u001B[0;32m--> 130\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43menv_i\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_wrapper_attr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod_name\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmethod_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmethod_kwargs\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m env_i \u001B[38;5;129;01min\u001B[39;00m target_envs]\n",
      "File \u001B[0;32m~/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/gymnasium/core.py:332\u001B[0m, in \u001B[0;36mWrapper.render\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    330\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mrender\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m RenderFrame \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mlist\u001B[39m[RenderFrame] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    331\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 332\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/gymnasium/wrappers/common.py:409\u001B[0m, in \u001B[0;36mOrderEnforcing.render\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    404\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_disable_render_order_enforcing \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_reset:\n\u001B[1;32m    405\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ResetNeeded(\n\u001B[1;32m    406\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot call `env.render()` before calling `env.reset()`, if this is an intended action, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    407\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mset `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    408\u001B[0m     )\n\u001B[0;32m--> 409\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/gymnasium/core.py:332\u001B[0m, in \u001B[0;36mWrapper.render\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    330\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mrender\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m RenderFrame \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mlist\u001B[39m[RenderFrame] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    331\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 332\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/gymnasium/wrappers/common.py:303\u001B[0m, in \u001B[0;36mPassiveEnvChecker.render\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    301\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m env_render_passive_checker(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menv)\n\u001B[1;32m    302\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 303\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_env.py:164\u001B[0m, in \u001B[0;36mMujocoEnv.render\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mrender\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    161\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;124;03m    Render a frame from the MuJoCo simulation as specified by the render_mode.\u001B[39;00m\n\u001B[1;32m    163\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 164\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmujoco_renderer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender_mode\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py:711\u001B[0m, in \u001B[0;36mMujocoRenderer.render\u001B[0;34m(self, render_mode)\u001B[0m\n\u001B[1;32m    709\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m viewer\u001B[38;5;241m.\u001B[39mrender(render_mode\u001B[38;5;241m=\u001B[39mrender_mode, camera_id\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcamera_id)\n\u001B[1;32m    710\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m render_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhuman\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 711\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mviewer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py:437\u001B[0m, in \u001B[0;36mWindowViewer.render\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    435\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_loop_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    436\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_loop_count \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 437\u001B[0m         \u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    438\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_loop_count \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    440\u001B[0m \u001B[38;5;66;03m# clear overlay\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/campus bio iscrizione/ Magistrale/Merone/RL/Reinforcement_Learning_Ant_MuJoCu/venv/lib/python3.10/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py:409\u001B[0m, in \u001B[0;36mWindowViewer.render.<locals>.update\u001B[0;34m()\u001B[0m\n\u001B[1;32m    407\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_hide_menu:\n\u001B[1;32m    408\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m gridpos, [t1, t2] \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_overlays\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m--> 409\u001B[0m         \u001B[43mmujoco\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmjr_overlay\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    410\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmujoco\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmjtFontScale\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmjFONTSCALE_150\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    411\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgridpos\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    412\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mviewport\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    413\u001B[0m \u001B[43m            \u001B[49m\u001B[43mt1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    414\u001B[0m \u001B[43m            \u001B[49m\u001B[43mt2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    415\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcon\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    416\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    418\u001B[0m glfw\u001B[38;5;241m.\u001B[39mswap_buffers(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwindow)\n\u001B[1;32m    419\u001B[0m glfw\u001B[38;5;241m.\u001B[39mpoll_events()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import time\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "\n",
    "import time  # Importazione necessaria per introdurre un ritardo nel rendering\n",
    "import gym  # Libreria per la creazione e gestione degli ambienti di reinforcement learning\n",
    "from stable_baselines3 import PPO  # Algoritmo PPO per il caricamento del modello\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize  # Strumenti per il preprocessing degli ambienti\n",
    "\n",
    "# Caricamento del modello PPO addestrato\n",
    "# Assicurati che il percorso al file sia corretto e che il modello esista\n",
    "model = PPO.load(\"ppo_HalfCheetah_model\")\n",
    "\n",
    "# Creazione dell'ambiente in modalità vettoriale con DummyVecEnv\n",
    "# Questo consente la compatibilità con le tecniche di normalizzazione come VecNormalize\n",
    "render_env = DummyVecEnv([lambda: gym.make(\"HalfCheetah-v5\",\n",
    "                                           reset_noise_scale=0.013459312664159742,  # Intensità del rumore alla reset\n",
    "                                           forward_reward_weight=1.4435374113892951,  # Peso della ricompensa per il movimento in avanti\n",
    "                                           ctrl_cost_weight=0.09129087622076545,  # Peso del costo del controllo (azione)\n",
    "                                           render_mode='human')])  # Modalità di rendering (può essere 'human' o 'rgb_array')\n",
    "\n",
    "# Caricamento della normalizzazione dello stato e delle ricompense\n",
    "# Assicurati che il percorso al file sia corretto e che il file di normalizzazione esista\n",
    "render_env = VecNormalize.load(\"vecnormalize_HalfCheetah.pkl\", render_env)\n",
    "\n",
    "# Disabilitiamo l'aggiornamento delle statistiche per la normalizzazione, utile in fase di test\n",
    "render_env.training = False\n",
    "render_env.norm_reward = True  # Se True, normalizza anche le ricompense\n",
    "\n",
    "# Reset dell'ambiente per ottenere l'osservazione iniziale (array numpy)\n",
    "obs = render_env.reset()\n",
    "\n",
    "done = False  # Variabile che indica se l'episodio è terminato\n",
    "\n",
    "# Loop per eseguire la simulazione e il rendering dell'ambiente\n",
    "while not done:\n",
    "    action, _ = model.predict(obs)  # Predizione dell'azione ottimale con il modello PPO\n",
    "    obs, rewards, dones, infos = render_env.step(action)  # Applichiamo l'azione e otteniamo i nuovi dati dall'ambiente\n",
    "    render_env.render()  # Visualizza l'ambiente a schermo (solo se render_mode='human')\n",
    "    time.sleep(0.01)  # Piccola pausa per rallentare il rendering e renderlo visibile\n",
    "\n",
    "    # Gestione del termine dell'episodio\n",
    "    # `dones` è un array (per compatibilità con più ambienti), prendiamo il primo valore\n",
    "    done = dones[0]\n",
    "\n",
    "# Chiusura dell'ambiente per rilasciare le risorse\n",
    "render_env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 43\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m frame \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     42\u001B[0m     cv2\u001B[38;5;241m.\u001B[39mimshow(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHalfCheetah Simulation\u001B[39m\u001B[38;5;124m\"\u001B[39m, frame)\n\u001B[0;32m---> 43\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwaitKey\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;241m&\u001B[39m \u001B[38;5;241m0xFF\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mord\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mq\u001B[39m\u001B[38;5;124m'\u001B[39m):  \u001B[38;5;66;03m# Premere 'q' per uscire\u001B[39;00m\n\u001B[1;32m     44\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m     45\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.01\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "\n",
    "# Carichiamo il modello PPO addestrato\n",
    "# Assicurati che il percorso del file sia corretto\n",
    "model = PPO.load(\"ppo_HalfCheetah_model\")\n",
    "\n",
    "# Funzione per creare l'ambiente personalizzato con i parametri specificati\n",
    "def make_env():\n",
    "    \"\"\"\n",
    "    Crea e restituisce l'ambiente \"HalfCheetah-v5\" dalla libreria Gym con i parametri specificati.\n",
    "\n",
    "    Questo ambiente viene configurato con valori personalizzati per:\n",
    "    - reset_noise_scale: livello di rumore al momento del reset dell'ambiente.\n",
    "    - forward_reward_weight: peso della ricompensa per il movimento in avanti.\n",
    "    - ctrl_cost_weight: peso del costo del controllo (energia utilizzata per il movimento).\n",
    "    - render_mode: impostato su 'rgb_array' per ottenere i frame in formato immagine.\n",
    "\n",
    "    Returns:\n",
    "        gym.Env: Un'istanza dell'ambiente \"HalfCheetah-v5\" configurata con i parametri specificati.\n",
    "    \"\"\"\n",
    "    env = gym.make(\"HalfCheetah-v5\",\n",
    "                   reset_noise_scale=0.013459312664159742,  # Intensità del rumore alla reset\n",
    "                   forward_reward_weight=1.4435374113892951,  # Peso della ricompensa per il movimento in avanti\n",
    "                   ctrl_cost_weight=0.09129087622076545,  # Peso del costo del controllo (azione)\n",
    "                   render_mode='rgb_array')  # Usa 'rgb_array' per ottenere i frame in formato immagine\n",
    "    return env\n",
    "\n",
    "# Creiamo un DummyVecEnv per avvolgere l'ambiente, necessario per l'uso di VecNormalize\n",
    "render_env = DummyVecEnv([make_env])\n",
    "\n",
    "# Carichiamo la normalizzazione salvata dallo stesso file usato durante l'addestramento\n",
    "# Assicurati che il percorso al file sia corretto\n",
    "render_env = VecNormalize.load(\"vecnormalize_HalfCheetah.pkl\", render_env)\n",
    "\n",
    "# Disattiviamo l'aggiornamento delle statistiche per la normalizzazione (utile in fase di valutazione)\n",
    "render_env.training = False\n",
    "render_env.norm_reward = True  # Se True, continua a normalizzare le ricompense\n",
    "\n",
    "# Reset dell'ambiente per ottenere l'osservazione iniziale (array numpy)\n",
    "obs = render_env.reset()\n",
    "done = False  # Variabile che indica se l'episodio è terminato\n",
    "\n",
    "# Loop per il rendering e la simulazione dell'agente\n",
    "while not done:\n",
    "    action, _ = model.predict(obs)  # Predizione dell'azione ottimale con il modello PPO\n",
    "    obs, reward, done, info = render_env.step(action)  # Esegui l'azione e ottieni i nuovi dati dall'ambiente\n",
    "\n",
    "    # Ottenere il frame dalla simulazione\n",
    "    frame = render_env.render()\n",
    "    if frame is not None:\n",
    "        cv2.imshow(\"HalfCheetah Simulation\", frame)  # Mostra il frame con OpenCV\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  # Premere 'q' per uscire dalla simulazione\n",
    "            break\n",
    "\n",
    "    time.sleep(0.01)  # Piccola pausa per migliorare la visualizzazione\n",
    "\n",
    "# Chiusura dell'ambiente e della finestra di visualizzazione\n",
    "render_env.close()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
